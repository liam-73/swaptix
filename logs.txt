* 
* ==> Audit <==
* |----------------|--------------------------------|----------|----------|---------|-----------------------|-----------------------|
|    Command     |              Args              | Profile  |   User   | Version |      Start Time       |       End Time        |
|----------------|--------------------------------|----------|----------|---------|-----------------------|-----------------------|
| kubectl        | -- apply -f client-depl.yaml   | minikube | liam     | v1.31.1 | 27 Jul 23 22:59 +0630 | 27 Jul 23 22:59 +0630 |
| kubectl        | -- get pods                    | minikube | liam     | v1.31.1 | 27 Jul 23 22:59 +0630 | 27 Jul 23 22:59 +0630 |
| kubectl        | -- apply -f ingress-srv.yaml   | minikube | liam     | v1.31.1 | 27 Jul 23 23:00 +0630 | 27 Jul 23 23:00 +0630 |
| ip             |                                | minikube | liam     | v1.31.1 | 27 Jul 23 23:01 +0630 | 27 Jul 23 23:01 +0630 |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 30 Jul 23 19:39 +0630 |                       |
|                | --user=skaffold                |          |          |         |                       |                       |
| start          |                                | minikube | liam     | v1.31.1 | 30 Jul 23 19:39 +0630 | 30 Jul 23 19:41 +0630 |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 03 Aug 23 00:17 +0630 |                       |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 20 Aug 23 22:07 +0630 |                       |
|                | --user=skaffold                |          |          |         |                       |                       |
| start          |                                | minikube | liam     | v1.31.1 | 20 Aug 23 22:09 +0630 |                       |
| start          |                                | minikube | liam     | v1.31.1 | 20 Aug 23 22:18 +0630 | 20 Aug 23 22:24 +0630 |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 20 Aug 23 22:25 +0630 | 20 Aug 23 22:25 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 20 Aug 23 22:32 +0630 | 20 Aug 23 22:32 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 20 Aug 23 22:33 +0630 | 20 Aug 23 22:33 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 21 Aug 23 01:05 +0630 |                       |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 21 Aug 23 01:13 +0630 |                       |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 21 Aug 23 01:15 +0630 |                       |
|                | --user=skaffold                |          |          |         |                       |                       |
| start          |                                | minikube | liam     | v1.31.1 | 21 Aug 23 01:16 +0630 | 21 Aug 23 01:17 +0630 |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 21 Aug 23 01:18 +0630 | 21 Aug 23 01:18 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 19 Nov 23 00:22 +0630 |                       |
|                | --user=skaffold                |          |          |         |                       |                       |
| start          |                                | minikube | liam     | v1.31.1 | 19 Nov 23 00:23 +0630 |                       |
| update-context |                                | minikube | liam     | v1.31.1 | 19 Nov 23 00:33 +0630 | 19 Nov 23 00:33 +0630 |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 19 Nov 23 00:35 +0630 | 19 Nov 23 00:35 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 19 Nov 23 00:46 +0630 | 19 Nov 23 00:46 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 19 Nov 23 00:49 +0630 | 19 Nov 23 00:49 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 19 Nov 23 00:50 +0630 | 19 Nov 23 00:50 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 19 Nov 23 01:04 +0630 | 19 Nov 23 01:04 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 25 Nov 23 00:03 +0630 |                       |
|                | --user=skaffold                |          |          |         |                       |                       |
| start          |                                | minikube | liam     | v1.31.1 | 25 Nov 23 00:22 +0630 |                       |
| start          |                                | minikube | liam     | v1.31.1 | 25 Nov 23 00:24 +0630 |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 25 Nov 23 00:27 +0630 | 25 Nov 23 00:27 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| update-check   |                                | minikube | liam     | v1.31.1 | 25 Nov 23 00:35 +0630 | 25 Nov 23 00:35 +0630 |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 25 Nov 23 00:38 +0630 | 25 Nov 23 00:38 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 25 Nov 23 00:38 +0630 | 25 Nov 23 00:38 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 25 Nov 23 00:39 +0630 | 25 Nov 23 00:39 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 25 Nov 23 00:42 +0630 | 25 Nov 23 00:42 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| stop           |                                | minikube | liam     | v1.31.1 | 25 Nov 23 00:57 +0630 | 25 Nov 23 00:57 +0630 |
| start          |                                | minikube | liam     | v1.31.1 | 25 Nov 23 00:57 +0630 |                       |
| ip             |                                | minikube | liam     | v1.31.1 | 25 Nov 23 01:07 +0630 | 25 Nov 23 01:07 +0630 |
| start          |                                | minikube | liam     | v1.31.1 | 25 Nov 23 14:22 +0630 |                       |
| update-check   |                                | minikube | liam     | v1.31.1 | 25 Nov 23 14:22 +0630 | 25 Nov 23 14:22 +0630 |
| start          |                                | minikube | liam     | v1.31.1 | 25 Nov 23 14:23 +0630 |                       |
| addons         | enable ingress                 | minikube | liam     | v1.31.1 | 25 Nov 23 15:22 +0630 |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.31.1 | 25 Nov 23 16:13 +0630 | 25 Nov 23 16:13 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| addons         | enable ingress                 | minikube | liam     | v1.31.1 | 25 Nov 23 16:18 +0630 |                       |
| addons         | enable ingress                 | minikube | liam     | v1.32.0 | 25 Nov 23 16:40 +0630 |                       |
| ip             |                                | minikube | liam     | v1.32.0 | 25 Nov 23 16:48 +0630 | 25 Nov 23 16:48 +0630 |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.32.0 | 25 Nov 23 16:57 +0630 | 25 Nov 23 16:57 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.32.0 | 25 Nov 23 17:11 +0630 | 25 Nov 23 17:11 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| update-check   |                                | minikube | liam     | v1.32.0 | 25 Nov 23 23:03 +0630 | 25 Nov 23 23:03 +0630 |
| update-check   |                                | minikube | liam     | v1.32.0 | 27 Nov 23 22:43 +0630 | 27 Nov 23 22:43 +0630 |
| start          |                                | minikube | liam     | v1.32.0 | 28 Nov 23 22:51 +0630 |                       |
| update-check   |                                | minikube | liam     | v1.32.0 | 28 Nov 23 22:56 +0630 | 28 Nov 23 22:56 +0630 |
| start          |                                | minikube | liam     | v1.32.0 | 28 Nov 23 23:02 +0630 |                       |
| update-context |                                | minikube | liam     | v1.32.0 | 28 Nov 23 23:13 +0630 | 28 Nov 23 23:13 +0630 |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.32.0 | 28 Nov 23 23:17 +0630 | 28 Nov 23 23:17 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.32.0 | 28 Nov 23 23:37 +0630 | 28 Nov 23 23:37 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| ip             |                                | minikube | liam     | v1.32.0 | 28 Nov 23 23:38 +0630 | 28 Nov 23 23:38 +0630 |
| start          |                                | minikube | liam     | v1.32.0 | 29 Nov 23 22:31 +0630 | 29 Nov 23 22:38 +0630 |
| docker-env     | --shell none -p minikube       | minikube | skaffold | v1.32.0 | 29 Nov 23 22:39 +0630 | 29 Nov 23 22:40 +0630 |
|                | --user=skaffold                |          |          |         |                       |                       |
| addons         | enable ingress                 | minikube | liam     | v1.32.0 | 29 Nov 23 22:52 +0630 |                       |
|----------------|--------------------------------|----------|----------|---------|-----------------------|-----------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/11/29 22:31:02
Running on machine: HP-430-G4
Binary: Built with gc go1.21.3 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1129 22:31:02.729326   13351 out.go:296] Setting OutFile to fd 1 ...
I1129 22:31:02.729505   13351 out.go:348] isatty.IsTerminal(1) = true
I1129 22:31:02.729511   13351 out.go:309] Setting ErrFile to fd 2...
I1129 22:31:02.729520   13351 out.go:348] isatty.IsTerminal(2) = true
I1129 22:31:02.729881   13351 root.go:338] Updating PATH: /home/liam/.minikube/bin
W1129 22:31:02.730557   13351 root.go:314] Error reading config file at /home/liam/.minikube/config/config.json: open /home/liam/.minikube/config/config.json: no such file or directory
I1129 22:31:02.732654   13351 out.go:303] Setting JSON to false
I1129 22:31:02.735755   13351 start.go:128] hostinfo: {"hostname":"HP-430-G4","uptime":16351,"bootTime":1701257312,"procs":339,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"22.04","kernelVersion":"6.2.0-37-generic","kernelArch":"x86_64","virtualizationSystem":"kvm","virtualizationRole":"host","hostId":"e2f69294-e2bb-42b2-ae27-0c8d612e8232"}
I1129 22:31:02.735854   13351 start.go:138] virtualization: kvm host
I1129 22:31:02.781238   13351 out.go:177] üòÑ  minikube v1.32.0 on Ubuntu 22.04
I1129 22:31:02.801240   13351 notify.go:220] Checking for updates...
I1129 22:31:02.803499   13351 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.3
I1129 22:31:02.853463   13351 out.go:177] üÜï  Kubernetes 1.28.3 is now available. If you would like to upgrade, specify: --kubernetes-version=v1.28.3
I1129 22:31:02.867788   13351 driver.go:378] Setting default libvirt URI to qemu:///system
I1129 22:31:03.229765   13351 docker.go:122] docker version: linux-24.0.6:Docker Desktop 4.25.2 (129061)
I1129 22:31:03.229894   13351 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I1129 22:31:08.639840   13351 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (5.409878505s)
I1129 22:31:08.641800   13351 info.go:266] docker info: {ID:5e96b263-07ed-4a33-8f96-5ee9272750f6 Containers:3 ContainersRunning:1 ContainersPaused:0 ContainersStopped:2 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:41 OomKillDisable:false NGoroutines:60 SystemTime:2023-11-29 16:01:08.477781965 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:9 KernelVersion:6.4.16-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:1974509568 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:linuxkit-525400123456 Labels:[] ExperimentalBuild:false ServerVersion:24.0.6 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:8165feabfdfe38c65b599c4993d227328c231fca Expected:8165feabfdfe38c65b599c4993d227328c231fca} RuncCommit:{ID:v1.1.8-0-g82f18fe Expected:v1.1.8-0-g82f18fe} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined name=cgroupns] ProductLicense: Warnings:[WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/lib/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.11.2-desktop.5] map[Name:compose Path:/usr/lib/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.23.0-desktop.1] map[Name:dev Path:/usr/lib/docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/usr/lib/docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.20] map[Name:init Path:/usr/lib/docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v0.1.0-beta.9] map[Name:sbom Path:/usr/lib/docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/usr/lib/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.26.0] map[Name:scout Path:/usr/lib/docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.0.9]] Warnings:<nil>}}
I1129 22:31:08.642191   13351 docker.go:295] overlay module found
I1129 22:31:08.653842   13351 out.go:177] ‚ú®  Using the docker driver based on existing profile
I1129 22:31:08.666567   13351 start.go:298] selected driver: docker
I1129 22:31:08.666584   13351 start.go:902] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.58.2 Port:8443 KubernetesVersion:v1.27.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true ingress:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/liam:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:0s GPUs:}
I1129 22:31:08.666832   13351 start.go:913] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I1129 22:31:08.667060   13351 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I1129 22:31:09.350870   13351 info.go:266] docker info: {ID:5e96b263-07ed-4a33-8f96-5ee9272750f6 Containers:3 ContainersRunning:1 ContainersPaused:0 ContainersStopped:2 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:42 OomKillDisable:false NGoroutines:62 SystemTime:2023-11-29 16:01:09.260561197 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:9 KernelVersion:6.4.16-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:1974509568 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:linuxkit-525400123456 Labels:[] ExperimentalBuild:false ServerVersion:24.0.6 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:8165feabfdfe38c65b599c4993d227328c231fca Expected:8165feabfdfe38c65b599c4993d227328c231fca} RuncCommit:{ID:v1.1.8-0-g82f18fe Expected:v1.1.8-0-g82f18fe} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined name=cgroupns] ProductLicense: Warnings:[WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/lib/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.11.2-desktop.5] map[Name:compose Path:/usr/lib/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.23.0-desktop.1] map[Name:dev Path:/usr/lib/docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/usr/lib/docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.20] map[Name:init Path:/usr/lib/docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v0.1.0-beta.9] map[Name:sbom Path:/usr/lib/docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/usr/lib/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.26.0] map[Name:scout Path:/usr/lib/docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.0.9]] Warnings:<nil>}}
I1129 22:31:09.358697   13351 cni.go:84] Creating CNI manager for ""
I1129 22:31:09.358755   13351 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1129 22:31:09.358789   13351 start_flags.go:323] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.58.2 Port:8443 KubernetesVersion:v1.27.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true ingress:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/liam:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:0s GPUs:}
I1129 22:31:09.397658   13351 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I1129 22:31:09.410815   13351 cache.go:121] Beginning downloading kic base image for docker with docker
I1129 22:31:09.423334   13351 out.go:177] üöú  Pulling base image ...
I1129 22:31:09.437004   13351 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 in local docker daemon
I1129 22:31:09.438571   13351 preload.go:132] Checking if preload exists for k8s version v1.27.3 and runtime docker
I1129 22:31:09.438683   13351 preload.go:148] Found local preload: /home/liam/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.3-docker-overlay2-amd64.tar.lz4
I1129 22:31:09.438700   13351 cache.go:56] Caching tarball of preloaded images
I1129 22:31:09.438994   13351 preload.go:174] Found /home/liam/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I1129 22:31:09.439033   13351 cache.go:59] Finished verifying existence of preloaded tar for  v1.27.3 on docker
I1129 22:31:09.439303   13351 profile.go:148] Saving config to /home/liam/.minikube/profiles/minikube/config.json ...
I1129 22:31:09.671877   13351 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 in local docker daemon, skipping pull
I1129 22:31:09.671899   13351 cache.go:144] gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 exists in daemon, skipping load
I1129 22:31:09.671930   13351 cache.go:194] Successfully downloaded all kic artifacts
I1129 22:31:09.679218   13351 start.go:365] acquiring machines lock for minikube: {Name:mk3ef2d0f8dcbaf5f7c37edc9b263bfef24a5993 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1129 22:31:09.679483   13351 start.go:369] acquired machines lock for "minikube" in 213.365¬µs
I1129 22:31:09.679519   13351 start.go:96] Skipping create...Using existing machine configuration
I1129 22:31:09.679528   13351 fix.go:54] fixHost starting: 
I1129 22:31:09.682984   13351 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1129 22:31:09.858358   13351 fix.go:102] recreateIfNeeded on minikube: state=Stopped err=<nil>
W1129 22:31:09.858392   13351 fix.go:128] unexpected machine state, will restart: <nil>
I1129 22:31:09.873085   13351 out.go:177] üîÑ  Restarting existing docker container for "minikube" ...
I1129 22:31:09.887730   13351 cli_runner.go:164] Run: docker start minikube
I1129 22:31:11.464454   13351 cli_runner.go:217] Completed: docker start minikube: (1.576644404s)
I1129 22:31:11.469818   13351 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1129 22:31:11.815455   13351 kic.go:430] container "minikube" state is running.
I1129 22:31:11.816383   13351 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1129 22:31:12.074858   13351 profile.go:148] Saving config to /home/liam/.minikube/profiles/minikube/config.json ...
I1129 22:31:12.075371   13351 machine.go:88] provisioning docker machine ...
I1129 22:31:12.076619   13351 ubuntu.go:169] provisioning hostname "minikube"
I1129 22:31:12.079346   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:12.351690   13351 main.go:141] libmachine: Using SSH client type: native
I1129 22:31:12.394990   13351 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 45187 <nil> <nil>}
I1129 22:31:12.395030   13351 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I1129 22:31:12.411811   13351 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: EOF
I1129 22:31:15.867156   13351 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I1129 22:31:15.873627   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:16.035820   13351 main.go:141] libmachine: Using SSH client type: native
I1129 22:31:16.036917   13351 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 45187 <nil> <nil>}
I1129 22:31:16.036984   13351 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I1129 22:31:16.256282   13351 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I1129 22:31:16.256653   13351 ubuntu.go:175] set auth options {CertDir:/home/liam/.minikube CaCertPath:/home/liam/.minikube/certs/ca.pem CaPrivateKeyPath:/home/liam/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/liam/.minikube/machines/server.pem ServerKeyPath:/home/liam/.minikube/machines/server-key.pem ClientKeyPath:/home/liam/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/liam/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/liam/.minikube}
I1129 22:31:16.256689   13351 ubuntu.go:177] setting up certificates
I1129 22:31:16.256708   13351 provision.go:83] configureAuth start
I1129 22:31:16.256832   13351 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1129 22:31:16.427316   13351 provision.go:138] copyHostCerts
I1129 22:31:16.446105   13351 exec_runner.go:144] found /home/liam/.minikube/ca.pem, removing ...
I1129 22:31:16.447380   13351 exec_runner.go:203] rm: /home/liam/.minikube/ca.pem
I1129 22:31:16.447521   13351 exec_runner.go:151] cp: /home/liam/.minikube/certs/ca.pem --> /home/liam/.minikube/ca.pem (1070 bytes)
I1129 22:31:16.452085   13351 exec_runner.go:144] found /home/liam/.minikube/cert.pem, removing ...
I1129 22:31:16.452100   13351 exec_runner.go:203] rm: /home/liam/.minikube/cert.pem
I1129 22:31:16.452166   13351 exec_runner.go:151] cp: /home/liam/.minikube/certs/cert.pem --> /home/liam/.minikube/cert.pem (1115 bytes)
I1129 22:31:16.456985   13351 exec_runner.go:144] found /home/liam/.minikube/key.pem, removing ...
I1129 22:31:16.456998   13351 exec_runner.go:203] rm: /home/liam/.minikube/key.pem
I1129 22:31:16.457057   13351 exec_runner.go:151] cp: /home/liam/.minikube/certs/key.pem --> /home/liam/.minikube/key.pem (1679 bytes)
I1129 22:31:16.459328   13351 provision.go:112] generating server cert: /home/liam/.minikube/machines/server.pem ca-key=/home/liam/.minikube/certs/ca.pem private-key=/home/liam/.minikube/certs/ca-key.pem org=liam.minikube san=[192.168.58.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I1129 22:31:16.889430   13351 provision.go:172] copyRemoteCerts
I1129 22:31:16.892697   13351 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I1129 22:31:16.892808   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:17.033333   13351 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:45187 SSHKeyPath:/home/liam/.minikube/machines/minikube/id_rsa Username:docker}
I1129 22:31:17.172996   13351 ssh_runner.go:362] scp /home/liam/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1070 bytes)
I1129 22:31:17.259797   13351 ssh_runner.go:362] scp /home/liam/.minikube/machines/server.pem --> /etc/docker/server.pem (1196 bytes)
I1129 22:31:17.333881   13351 ssh_runner.go:362] scp /home/liam/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I1129 22:31:17.415203   13351 provision.go:86] duration metric: configureAuth took 1.157181241s
I1129 22:31:17.415229   13351 ubuntu.go:193] setting minikube options for container-runtime
I1129 22:31:17.424640   13351 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.3
I1129 22:31:17.424819   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:17.553329   13351 main.go:141] libmachine: Using SSH client type: native
I1129 22:31:17.554070   13351 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 45187 <nil> <nil>}
I1129 22:31:17.554096   13351 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I1129 22:31:17.762974   13351 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I1129 22:31:17.762995   13351 ubuntu.go:71] root file system type: overlay
I1129 22:31:17.765130   13351 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I1129 22:31:17.766368   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:17.900784   13351 main.go:141] libmachine: Using SSH client type: native
I1129 22:31:17.901699   13351 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 45187 <nil> <nil>}
I1129 22:31:17.901929   13351 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I1129 22:31:18.133855   13351 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I1129 22:31:18.134015   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:18.289462   13351 main.go:141] libmachine: Using SSH client type: native
I1129 22:31:18.290452   13351 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 45187 <nil> <nil>}
I1129 22:31:18.290527   13351 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I1129 22:31:18.519577   13351 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I1129 22:31:18.519597   13351 machine.go:91] provisioned docker machine in 6.444209886s
I1129 22:31:18.519645   13351 start.go:300] post-start starting for "minikube" (driver="docker")
I1129 22:31:18.519680   13351 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I1129 22:31:18.519839   13351 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I1129 22:31:18.519978   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:18.667251   13351 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:45187 SSHKeyPath:/home/liam/.minikube/machines/minikube/id_rsa Username:docker}
I1129 22:31:18.815393   13351 ssh_runner.go:195] Run: cat /etc/os-release
I1129 22:31:18.823987   13351 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I1129 22:31:18.824078   13351 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I1129 22:31:18.824113   13351 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I1129 22:31:18.824124   13351 info.go:137] Remote host: Ubuntu 22.04.2 LTS
I1129 22:31:18.824140   13351 filesync.go:126] Scanning /home/liam/.minikube/addons for local assets ...
I1129 22:31:18.824643   13351 filesync.go:126] Scanning /home/liam/.minikube/files for local assets ...
I1129 22:31:18.824922   13351 start.go:303] post-start completed in 305.264591ms
I1129 22:31:18.825045   13351 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I1129 22:31:18.825135   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:18.947412   13351 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:45187 SSHKeyPath:/home/liam/.minikube/machines/minikube/id_rsa Username:docker}
I1129 22:31:19.077672   13351 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I1129 22:31:19.087807   13351 fix.go:56] fixHost completed within 9.408270957s
I1129 22:31:19.087830   13351 start.go:83] releasing machines lock for "minikube", held for 9.408330096s
I1129 22:31:19.087995   13351 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1129 22:31:19.207908   13351 ssh_runner.go:195] Run: cat /version.json
I1129 22:31:19.207997   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:19.209027   13351 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I1129 22:31:19.209854   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:31:19.333596   13351 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:45187 SSHKeyPath:/home/liam/.minikube/machines/minikube/id_rsa Username:docker}
I1129 22:31:19.354205   13351 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:45187 SSHKeyPath:/home/liam/.minikube/machines/minikube/id_rsa Username:docker}
W1129 22:31:19.470661   13351 out.go:239] ‚ùó  Image was not built for the current minikube version. To resolve this you can delete and recreate your minikube cluster using the latest images. Expected minikube version: v1.31.0 -> Actual minikube version: v1.32.0
I1129 22:31:19.473510   13351 ssh_runner.go:195] Run: systemctl --version
I1129 22:31:19.996411   13351 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I1129 22:31:20.011326   13351 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I1129 22:31:20.060873   13351 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I1129 22:31:20.061026   13351 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I1129 22:31:20.081628   13351 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I1129 22:31:20.081654   13351 start.go:472] detecting cgroup driver to use...
I1129 22:31:20.081701   13351 detect.go:199] detected "systemd" cgroup driver on host os
I1129 22:31:20.083930   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I1129 22:31:20.119131   13351 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I1129 22:31:20.143620   13351 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I1129 22:31:20.164308   13351 containerd.go:145] configuring containerd to use "systemd" as cgroup driver...
I1129 22:31:20.164502   13351 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = true|g' /etc/containerd/config.toml"
I1129 22:31:20.185948   13351 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1129 22:31:20.206928   13351 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I1129 22:31:20.227366   13351 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1129 22:31:20.249418   13351 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I1129 22:31:20.271879   13351 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I1129 22:31:20.295141   13351 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I1129 22:31:20.318889   13351 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I1129 22:31:20.343177   13351 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1129 22:31:20.521607   13351 ssh_runner.go:195] Run: sudo systemctl restart containerd
I1129 22:31:20.667347   13351 start.go:472] detecting cgroup driver to use...
I1129 22:31:20.667397   13351 detect.go:199] detected "systemd" cgroup driver on host os
I1129 22:31:20.667509   13351 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I1129 22:31:20.698762   13351 cruntime.go:279] skipping containerd shutdown because we are bound to it
I1129 22:31:20.698924   13351 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I1129 22:31:20.736160   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I1129 22:31:20.778919   13351 ssh_runner.go:195] Run: which cri-dockerd
I1129 22:31:20.792932   13351 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I1129 22:31:20.820740   13351 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I1129 22:31:20.867032   13351 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I1129 22:31:21.071668   13351 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I1129 22:31:21.271087   13351 docker.go:560] configuring docker to use "systemd" as cgroup driver...
I1129 22:31:21.274967   13351 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (129 bytes)
I1129 22:31:21.330747   13351 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1129 22:31:21.531636   13351 ssh_runner.go:195] Run: sudo systemctl restart docker
I1129 22:31:22.668982   13351 ssh_runner.go:235] Completed: sudo systemctl restart docker: (1.137307663s)
I1129 22:31:22.669114   13351 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I1129 22:31:22.844814   13351 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I1129 22:31:23.009471   13351 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I1129 22:31:23.190178   13351 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1129 22:31:23.389608   13351 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I1129 22:31:23.441722   13351 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1129 22:31:23.642046   13351 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I1129 22:31:24.297667   13351 start.go:519] Will wait 60s for socket path /var/run/cri-dockerd.sock
I1129 22:31:24.297885   13351 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I1129 22:31:24.314275   13351 start.go:540] Will wait 60s for crictl version
I1129 22:31:24.314444   13351 ssh_runner.go:195] Run: which crictl
I1129 22:31:24.326793   13351 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I1129 22:31:24.745859   13351 start.go:556] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  24.0.4
RuntimeApiVersion:  v1
I1129 22:31:24.745977   13351 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1129 22:31:24.986782   13351 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1129 22:31:25.066087   13351 out.go:204] üê≥  Preparing Kubernetes v1.27.3 on Docker 24.0.4 ...
I1129 22:31:25.068968   13351 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I1129 22:31:25.193463   13351 ssh_runner.go:195] Run: grep 192.168.58.1	host.minikube.internal$ /etc/hosts
I1129 22:31:25.205931   13351 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.58.1	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I1129 22:31:25.240986   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I1129 22:31:25.366354   13351 preload.go:132] Checking if preload exists for k8s version v1.27.3 and runtime docker
I1129 22:31:25.366500   13351 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1129 22:31:25.423118   13351 docker.go:671] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.27.3
registry.k8s.io/kube-scheduler:v1.27.3
registry.k8s.io/kube-proxy:v1.27.3
registry.k8s.io/kube-controller-manager:v1.27.3
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/etcd:3.5.7-0
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I1129 22:31:25.423146   13351 docker.go:601] Images already preloaded, skipping extraction
I1129 22:31:25.424429   13351 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1129 22:31:25.475447   13351 docker.go:671] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.27.3
registry.k8s.io/kube-scheduler:v1.27.3
registry.k8s.io/kube-proxy:v1.27.3
registry.k8s.io/kube-controller-manager:v1.27.3
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/etcd:3.5.7-0
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I1129 22:31:25.477041   13351 cache_images.go:84] Images are preloaded, skipping loading
I1129 22:31:25.478333   13351 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I1129 22:31:26.033693   13351 cni.go:84] Creating CNI manager for ""
I1129 22:31:26.033732   13351 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1129 22:31:26.036455   13351 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I1129 22:31:26.036531   13351 kubeadm.go:176] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.58.2 APIServerPort:8443 KubernetesVersion:v1.27.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.58.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.58.2 CgroupDriver:systemd ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I1129 22:31:26.041444   13351 kubeadm.go:181] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.58.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.58.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.58.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.27.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: systemd
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I1129 22:31:26.041623   13351 kubeadm.go:976] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.27.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.58.2

[Install]
 config:
{KubernetesVersion:v1.27.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I1129 22:31:26.041747   13351 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.27.3
I1129 22:31:26.073044   13351 binaries.go:44] Found k8s binaries, skipping transfer
I1129 22:31:26.073238   13351 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I1129 22:31:26.113594   13351 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (369 bytes)
I1129 22:31:26.167471   13351 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I1129 22:31:26.218505   13351 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2090 bytes)
I1129 22:31:26.270905   13351 ssh_runner.go:195] Run: grep 192.168.58.2	control-plane.minikube.internal$ /etc/hosts
I1129 22:31:26.283454   13351 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.58.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I1129 22:31:26.320635   13351 certs.go:56] Setting up /home/liam/.minikube/profiles/minikube for IP: 192.168.58.2
I1129 22:31:26.320693   13351 certs.go:190] acquiring lock for shared ca certs: {Name:mk958f61f8c251bbeb42c4788bc23770c3bba158 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1129 22:31:26.321575   13351 certs.go:199] skipping minikubeCA CA generation: /home/liam/.minikube/ca.key
I1129 22:31:26.322065   13351 certs.go:199] skipping proxyClientCA CA generation: /home/liam/.minikube/proxy-client-ca.key
I1129 22:31:26.322660   13351 certs.go:315] skipping minikube-user signed cert generation: /home/liam/.minikube/profiles/minikube/client.key
I1129 22:31:26.323335   13351 certs.go:315] skipping minikube signed cert generation: /home/liam/.minikube/profiles/minikube/apiserver.key.cee25041
I1129 22:31:26.323745   13351 certs.go:315] skipping aggregator signed cert generation: /home/liam/.minikube/profiles/minikube/proxy-client.key
I1129 22:31:26.324207   13351 certs.go:437] found cert: /home/liam/.minikube/certs/home/liam/.minikube/certs/ca-key.pem (1675 bytes)
I1129 22:31:26.324299   13351 certs.go:437] found cert: /home/liam/.minikube/certs/home/liam/.minikube/certs/ca.pem (1070 bytes)
I1129 22:31:26.324407   13351 certs.go:437] found cert: /home/liam/.minikube/certs/home/liam/.minikube/certs/cert.pem (1115 bytes)
I1129 22:31:26.324491   13351 certs.go:437] found cert: /home/liam/.minikube/certs/home/liam/.minikube/certs/key.pem (1679 bytes)
I1129 22:31:26.341813   13351 ssh_runner.go:362] scp /home/liam/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I1129 22:31:26.417867   13351 ssh_runner.go:362] scp /home/liam/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I1129 22:31:26.499172   13351 ssh_runner.go:362] scp /home/liam/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I1129 22:31:26.571670   13351 ssh_runner.go:362] scp /home/liam/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I1129 22:31:26.642954   13351 ssh_runner.go:362] scp /home/liam/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I1129 22:31:26.710559   13351 ssh_runner.go:362] scp /home/liam/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I1129 22:31:26.781652   13351 ssh_runner.go:362] scp /home/liam/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I1129 22:31:26.857744   13351 ssh_runner.go:362] scp /home/liam/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I1129 22:31:26.945002   13351 ssh_runner.go:362] scp /home/liam/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I1129 22:31:27.051350   13351 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (742 bytes)
I1129 22:31:27.123546   13351 ssh_runner.go:195] Run: openssl version
I1129 22:31:27.156706   13351 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I1129 22:31:27.198295   13351 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I1129 22:31:27.214050   13351 certs.go:480] hashing: -rw-r--r-- 1 root root 1111 Jul 20 18:48 /usr/share/ca-certificates/minikubeCA.pem
I1129 22:31:27.214217   13351 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I1129 22:31:27.237861   13351 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I1129 22:31:27.272187   13351 ssh_runner.go:195] Run: ls /var/lib/minikube/certs/etcd
I1129 22:31:27.287126   13351 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I1129 22:31:27.319536   13351 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I1129 22:31:27.342930   13351 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I1129 22:31:27.366384   13351 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I1129 22:31:27.394868   13351 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I1129 22:31:27.421895   13351 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I1129 22:31:27.457570   13351 kubeadm.go:404] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.58.2 Port:8443 KubernetesVersion:v1.27.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true ingress:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/liam:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:0s GPUs:}
I1129 22:31:27.457933   13351 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I1129 22:31:27.522311   13351 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I1129 22:31:27.560978   13351 kubeadm.go:419] found existing configuration files, will attempt cluster restart
I1129 22:31:27.561002   13351 kubeadm.go:636] restartCluster start
I1129 22:31:27.561199   13351 ssh_runner.go:195] Run: sudo test -d /data/minikube
I1129 22:31:27.600075   13351 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I1129 22:31:27.600286   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I1129 22:31:27.783293   13351 kubeconfig.go:92] found "minikube" server: "https://127.0.0.1:32927"
I1129 22:31:27.783324   13351 kubeconfig.go:135] verify returned: got: 127.0.0.1:32927, want: 127.0.0.1:39323
I1129 22:31:27.793799   13351 lock.go:35] WriteFile acquiring /home/liam/.kube/config: {Name:mkaf45df65a8c393d5c318e99790e95d6771c361 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1129 22:31:27.826927   13351 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I1129 22:31:27.862778   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:27.863009   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:27.916318   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:27.916343   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:27.916516   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:27.955343   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:28.456021   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:28.456272   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:28.500395   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:28.956179   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:28.956378   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:28.996701   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:29.456416   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:29.456608   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:29.501055   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:29.956142   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:29.956383   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:30.007601   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:30.455717   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:30.455910   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:30.517542   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:30.955497   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:30.955642   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:30.996237   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:31.455585   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:31.455791   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:31.508786   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:31.956144   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:31.956328   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:32.021262   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:32.456403   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:32.456582   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:32.573855   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:32.955999   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:32.956158   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:32.984251   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:33.455809   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:33.455963   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:33.494903   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:33.955714   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:33.955841   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:34.002825   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:34.456196   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:34.456365   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:34.500536   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:34.955953   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:34.956135   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:35.009733   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:35.455964   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:35.456090   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:35.498401   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:35.955500   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:35.955730   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:35.992712   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:36.456288   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:36.456413   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:36.510793   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:36.956199   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:36.956423   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:36.998168   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:37.511338   13351 api_server.go:166] Checking apiserver status ...
I1129 22:31:37.511480   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1129 22:31:37.550103   13351 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1129 22:31:37.863109   13351 kubeadm.go:611] needs reconfigure: apiserver error: context deadline exceeded
I1129 22:31:37.863146   13351 kubeadm.go:1128] stopping kube-system containers ...
I1129 22:31:37.864445   13351 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I1129 22:31:37.942257   13351 docker.go:469] Stopping containers: [5d494ce9fe5d f5d3dac36390 0ae9b23fe5c5 8ab073a12072 fabfae8af6ab 947d676d9446 b1bfe67fba6e d714f7b478cf 24127f25fe1a f32fae356c21]
I1129 22:31:37.942467   13351 ssh_runner.go:195] Run: docker stop 5d494ce9fe5d f5d3dac36390 0ae9b23fe5c5 8ab073a12072 fabfae8af6ab 947d676d9446 b1bfe67fba6e d714f7b478cf 24127f25fe1a f32fae356c21
I1129 22:31:38.006483   13351 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I1129 22:31:38.053534   13351 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I1129 22:31:38.108052   13351 kubeadm.go:155] found existing configuration files:
-rw------- 1 root root 5639 Nov 28 16:39 /etc/kubernetes/admin.conf
-rw------- 1 root root 5656 Nov 28 16:39 /etc/kubernetes/controller-manager.conf
-rw------- 1 root root 5659 Nov 28 16:39 /etc/kubernetes/kubelet.conf
-rw------- 1 root root 5604 Nov 28 16:39 /etc/kubernetes/scheduler.conf

I1129 22:31:38.108235   13351 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I1129 22:31:38.140505   13351 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I1129 22:31:38.175367   13351 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I1129 22:31:38.217520   13351 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 1
stdout:

stderr:
I1129 22:31:38.217716   13351 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I1129 22:31:38.248097   13351 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I1129 22:31:38.279838   13351 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 1
stdout:

stderr:
I1129 22:31:38.280024   13351 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I1129 22:31:38.320111   13351 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I1129 22:31:38.354088   13351 kubeadm.go:713] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I1129 22:31:38.354200   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I1129 22:31:39.070509   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I1129 22:31:41.869285   13351 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml": (2.798572024s)
I1129 22:31:41.869317   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.3:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I1129 22:31:42.413723   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.3:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I1129 22:31:42.647866   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.3:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I1129 22:31:42.816927   13351 api_server.go:52] waiting for apiserver process to appear ...
I1129 22:31:42.817118   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:42.871903   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:43.434901   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:43.934518   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:44.434318   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:44.933964   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:45.433802   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:45.933679   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:46.434659   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:46.933715   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:47.433867   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:47.934534   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:48.613282   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:48.933712   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:49.434504   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:49.934128   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:50.434023   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:50.934539   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:51.434068   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:51.933743   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:52.434085   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:52.934324   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:54.207863   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:54.434189   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:54.934633   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:55.433924   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:55.934593   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:56.434007   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:56.935153   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:57.434576   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:57.935360   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:58.434849   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:58.934968   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:59.434314   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:31:59.934122   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:32:00.433800   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:32:00.933756   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:32:01.435538   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:32:01.521290   13351 api_server.go:72] duration metric: took 18.704358723s to wait for apiserver process to appear ...
I1129 22:32:01.521317   13351 api_server.go:88] waiting for apiserver healthz status ...
I1129 22:32:01.521350   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:01.558885   13351 api_server.go:269] stopped: https://127.0.0.1:39323/healthz: Get "https://127.0.0.1:39323/healthz": EOF
I1129 22:32:01.558930   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:01.562694   13351 api_server.go:269] stopped: https://127.0.0.1:39323/healthz: Get "https://127.0.0.1:39323/healthz": EOF
I1129 22:32:02.063185   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:02.066110   13351 api_server.go:269] stopped: https://127.0.0.1:39323/healthz: Get "https://127.0.0.1:39323/healthz": EOF
I1129 22:32:02.563400   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:02.567513   13351 api_server.go:269] stopped: https://127.0.0.1:39323/healthz: Get "https://127.0.0.1:39323/healthz": EOF
I1129 22:32:03.063140   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:03.066446   13351 api_server.go:269] stopped: https://127.0.0.1:39323/healthz: Get "https://127.0.0.1:39323/healthz": EOF
I1129 22:32:03.563294   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:03.566835   13351 api_server.go:269] stopped: https://127.0.0.1:39323/healthz: Get "https://127.0.0.1:39323/healthz": EOF
I1129 22:32:04.063006   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:04.065963   13351 api_server.go:269] stopped: https://127.0.0.1:39323/healthz: Get "https://127.0.0.1:39323/healthz": EOF
I1129 22:32:04.582694   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:04.611150   13351 api_server.go:269] stopped: https://127.0.0.1:39323/healthz: Get "https://127.0.0.1:39323/healthz": EOF
I1129 22:32:05.063591   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:10.064339   13351 api_server.go:269] stopped: https://127.0.0.1:39323/healthz: Get "https://127.0.0.1:39323/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I1129 22:32:10.064393   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:11.858147   13351 api_server.go:279] https://127.0.0.1:39323/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W1129 22:32:11.858173   13351 api_server.go:103] status: https://127.0.0.1:39323/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I1129 22:32:11.858196   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:12.043410   13351 api_server.go:279] https://127.0.0.1:39323/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W1129 22:32:12.043450   13351 api_server.go:103] status: https://127.0.0.1:39323/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I1129 22:32:12.063805   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:12.116600   13351 api_server.go:279] https://127.0.0.1:39323/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[+]poststarthook/start-system-namespaces-controller ok
[-]poststarthook/bootstrap-controller failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[-]poststarthook/apiservice-registration-controller failed: reason withheld
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W1129 22:32:12.116652   13351 api_server.go:103] status: https://127.0.0.1:39323/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[+]poststarthook/start-system-namespaces-controller ok
[-]poststarthook/bootstrap-controller failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[-]poststarthook/apiservice-registration-controller failed: reason withheld
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I1129 22:32:12.563401   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:12.601192   13351 api_server.go:279] https://127.0.0.1:39323/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W1129 22:32:12.601234   13351 api_server.go:103] status: https://127.0.0.1:39323/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I1129 22:32:13.063297   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:13.104718   13351 api_server.go:279] https://127.0.0.1:39323/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W1129 22:32:13.104751   13351 api_server.go:103] status: https://127.0.0.1:39323/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I1129 22:32:13.562873   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:13.586939   13351 api_server.go:279] https://127.0.0.1:39323/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W1129 22:32:13.586980   13351 api_server.go:103] status: https://127.0.0.1:39323/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I1129 22:32:14.062807   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:14.076865   13351 api_server.go:279] https://127.0.0.1:39323/healthz returned 200:
ok
I1129 22:32:14.109142   13351 api_server.go:141] control plane version: v1.27.3
I1129 22:32:14.109167   13351 api_server.go:131] duration metric: took 12.587837971s to wait for apiserver health ...
I1129 22:32:14.109179   13351 cni.go:84] Creating CNI manager for ""
I1129 22:32:14.109205   13351 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1129 22:32:14.117732   13351 out.go:177] üîó  Configuring bridge CNI (Container Networking Interface) ...
I1129 22:32:14.128406   13351 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I1129 22:32:14.191497   13351 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I1129 22:32:14.336571   13351 system_pods.go:43] waiting for kube-system pods to appear ...
I1129 22:32:14.428286   13351 system_pods.go:59] 4 kube-system pods found
I1129 22:32:14.428344   13351 system_pods.go:61] "etcd-minikube" [63f45099-73bb-4802-88bd-fca4438d7d27] Running
I1129 22:32:14.428360   13351 system_pods.go:61] "kube-apiserver-minikube" [327db430-17c0-4272-a3ec-f1726f3894e6] Running
I1129 22:32:14.428374   13351 system_pods.go:61] "kube-controller-manager-minikube" [179a1521-352a-4cbc-8ec8-9e0c91d29217] Running
I1129 22:32:14.428389   13351 system_pods.go:61] "kube-scheduler-minikube" [e18242c3-a910-445b-9a00-333a9cc23854] Running
I1129 22:32:14.428401   13351 system_pods.go:74] duration metric: took 91.807213ms to wait for pod list to return data ...
I1129 22:32:14.428415   13351 node_conditions.go:102] verifying NodePressure condition ...
I1129 22:32:14.499034   13351 node_conditions.go:122] node storage ephemeral capacity is 65739308Ki
I1129 22:32:14.499103   13351 node_conditions.go:123] node cpu capacity is 4
I1129 22:32:14.499136   13351 node_conditions.go:105] duration metric: took 70.707218ms to run NodePressure ...
I1129 22:32:14.499171   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml"
I1129 22:32:15.173575   13351 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I1129 22:32:15.214544   13351 ops.go:34] apiserver oom_adj: -16
I1129 22:32:15.214568   13351 kubeadm.go:640] restartCluster took 47.653551076s
I1129 22:32:15.214585   13351 kubeadm.go:406] StartCluster complete in 47.757029768s
I1129 22:32:15.214625   13351 settings.go:142] acquiring lock: {Name:mk60799a66a0fd8f5c12091fb0da79ac20b91181 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1129 22:32:15.214909   13351 settings.go:150] Updating kubeconfig:  /home/liam/.kube/config
I1129 22:32:15.219902   13351 lock.go:35] WriteFile acquiring /home/liam/.kube/config: {Name:mkaf45df65a8c393d5c318e99790e95d6771c361 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1129 22:32:15.222559   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.27.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I1129 22:32:15.224233   13351 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.3
I1129 22:32:15.226584   13351 addons.go:499] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:true ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volumesnapshots:false]
I1129 22:32:15.226820   13351 addons.go:69] Setting default-storageclass=true in profile "minikube"
I1129 22:32:15.226846   13351 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I1129 22:32:15.226859   13351 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I1129 22:32:15.226883   13351 addons.go:231] Setting addon storage-provisioner=true in "minikube"
W1129 22:32:15.226900   13351 addons.go:240] addon storage-provisioner should already be in state true
I1129 22:32:15.227572   13351 addons.go:69] Setting dashboard=true in profile "minikube"
I1129 22:32:15.227584   13351 addons.go:69] Setting ingress=true in profile "minikube"
I1129 22:32:15.227609   13351 addons.go:231] Setting addon ingress=true in "minikube"
W1129 22:32:15.227628   13351 addons.go:240] addon ingress should already be in state true
I1129 22:32:15.227796   13351 addons.go:231] Setting addon dashboard=true in "minikube"
W1129 22:32:15.227816   13351 addons.go:240] addon dashboard should already be in state true
I1129 22:32:15.227820   13351 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1129 22:32:15.232290   13351 host.go:66] Checking if "minikube" exists ...
I1129 22:32:15.232290   13351 host.go:66] Checking if "minikube" exists ...
I1129 22:32:15.233613   13351 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1129 22:32:15.233613   13351 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1129 22:32:15.234022   13351 host.go:66] Checking if "minikube" exists ...
I1129 22:32:15.235275   13351 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1129 22:32:15.386792   13351 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I1129 22:32:15.386840   13351 start.go:223] Will wait 6m0s for node &{Name: IP:192.168.58.2 Port:8443 KubernetesVersion:v1.27.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I1129 22:32:15.396626   13351 out.go:177] üîé  Verifying Kubernetes components...
I1129 22:32:15.413145   13351 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I1129 22:32:15.671977   13351 out.go:177]     ‚ñ™ Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0
I1129 22:32:15.680783   13351 addons.go:231] Setting addon default-storageclass=true in "minikube"
I1129 22:32:15.727566   13351 out.go:177]     ‚ñ™ Using image docker.io/kubernetesui/metrics-scraper:v1.0.8
I1129 22:32:15.701217   13351 out.go:177]     ‚ñ™ Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0
W1129 22:32:15.701259   13351 addons.go:240] addon default-storageclass should already be in state true
I1129 22:32:15.751871   13351 host.go:66] Checking if "minikube" exists ...
I1129 22:32:15.792378   13351 out.go:177]     ‚ñ™ Using image docker.io/kubernetesui/dashboard:v2.7.0
I1129 22:32:15.770332   13351 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I1129 22:32:15.775772   13351 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1129 22:32:15.812538   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-ns.yaml
I1129 22:32:15.835282   13351 out.go:177]     ‚ñ™ Using image registry.k8s.io/ingress-nginx/controller:v1.9.4
I1129 22:32:15.851836   13351 addons.go:423] installing /etc/kubernetes/addons/storage-provisioner.yaml
I1129 22:32:15.851860   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I1129 22:32:15.852051   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:32:15.852460   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-ns.yaml (759 bytes)
I1129 22:32:15.852615   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:32:15.884095   13351 addons.go:423] installing /etc/kubernetes/addons/ingress-deploy.yaml
I1129 22:32:15.884123   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/ingress-deploy.yaml (16103 bytes)
I1129 22:32:15.884277   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:32:16.161854   13351 addons.go:423] installing /etc/kubernetes/addons/storageclass.yaml
I1129 22:32:16.161883   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I1129 22:32:16.162018   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1129 22:32:16.250554   13351 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:45187 SSHKeyPath:/home/liam/.minikube/machines/minikube/id_rsa Username:docker}
I1129 22:32:16.290468   13351 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:45187 SSHKeyPath:/home/liam/.minikube/machines/minikube/id_rsa Username:docker}
I1129 22:32:16.309323   13351 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:45187 SSHKeyPath:/home/liam/.minikube/machines/minikube/id_rsa Username:docker}
I1129 22:32:16.432169   13351 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:45187 SSHKeyPath:/home/liam/.minikube/machines/minikube/id_rsa Username:docker}
I1129 22:32:16.684559   13351 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I1129 22:32:16.687637   13351 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.3/kubectl apply -f /etc/kubernetes/addons/ingress-deploy.yaml
I1129 22:32:16.689531   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-clusterrole.yaml
I1129 22:32:16.689552   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-clusterrole.yaml (1001 bytes)
I1129 22:32:16.822328   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml
I1129 22:32:16.822348   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml (1018 bytes)
I1129 22:32:16.829438   13351 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I1129 22:32:16.908458   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-configmap.yaml
I1129 22:32:16.908479   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-configmap.yaml (837 bytes)
I1129 22:32:16.991133   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-dp.yaml
I1129 22:32:16.991151   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-dp.yaml (4288 bytes)
I1129 22:32:17.057399   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-role.yaml
I1129 22:32:17.057426   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-role.yaml (1724 bytes)
I1129 22:32:17.072293   13351 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.27.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml": (1.849699259s)
I1129 22:32:17.072618   13351 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.27.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed -e '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.58.1 host.minikube.internal\n           fallthrough\n        }' -e '/^        errors *$/i \        log' | sudo /var/lib/minikube/binaries/v1.27.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I1129 22:32:17.072724   13351 ssh_runner.go:235] Completed: sudo systemctl is-active --quiet service kubelet: (1.659553401s)
I1129 22:32:17.072850   13351 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I1129 22:32:17.289923   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-rolebinding.yaml
I1129 22:32:17.289954   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-rolebinding.yaml (1046 bytes)
I1129 22:32:17.403123   13351 api_server.go:52] waiting for apiserver process to appear ...
I1129 22:32:17.403264   13351 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1129 22:32:17.523896   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-sa.yaml
I1129 22:32:17.523925   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-sa.yaml (837 bytes)
I1129 22:32:17.745723   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-secret.yaml
I1129 22:32:17.746277   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-secret.yaml (1389 bytes)
I1129 22:32:17.950722   13351 addons.go:423] installing /etc/kubernetes/addons/dashboard-svc.yaml
I1129 22:32:17.950743   13351 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-svc.yaml (1294 bytes)
I1129 22:32:18.076673   13351 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.3/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I1129 22:32:27.106246   13351 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.3/kubectl apply -f /etc/kubernetes/addons/ingress-deploy.yaml: (10.418557711s)
I1129 22:32:27.106657   13351 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (10.422068361s)
I1129 22:32:27.106747   13351 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: (10.277279232s)
I1129 22:32:27.106872   13351 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.27.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed -e '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.58.1 host.minikube.internal\n           fallthrough\n        }' -e '/^        errors *$/i \        log' | sudo /var/lib/minikube/binaries/v1.27.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -": (10.034223723s)
I1129 22:32:27.106896   13351 start.go:926] {"host.minikube.internal": 192.168.58.1} host record injected into CoreDNS's ConfigMap
I1129 22:32:27.106980   13351 ssh_runner.go:235] Completed: sudo pgrep -xnf kube-apiserver.*minikube.*: (9.703698505s)
I1129 22:32:27.107000   13351 api_server.go:72] duration metric: took 11.720101912s to wait for apiserver process to appear ...
I1129 22:32:27.107009   13351 api_server.go:88] waiting for apiserver healthz status ...
I1129 22:32:27.107039   13351 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:39323/healthz ...
I1129 22:32:27.107732   13351 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.3/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: (9.031009595s)
I1129 22:32:27.151974   13351 out.go:177] üí°  Some dashboard features require the metrics-server addon. To enable all features please run:

	minikube addons enable metrics-server	


I1129 22:32:27.127171   13351 addons.go:467] Verifying addon ingress=true in "minikube"
I1129 22:32:27.169802   13351 out.go:177] üîé  Verifying ingress addon...
I1129 22:32:27.200853   13351 kapi.go:75] Waiting for pod with label "app.kubernetes.io/name=ingress-nginx" in ns "ingress-nginx" ...
I1129 22:32:27.321468   13351 kapi.go:86] Found 0 Pods for label selector app.kubernetes.io/name=ingress-nginx
I1129 22:32:27.371921   13351 api_server.go:279] https://127.0.0.1:39323/healthz returned 200:
ok
I1129 22:32:27.401786   13351 api_server.go:141] control plane version: v1.27.3
I1129 22:32:27.401808   13351 api_server.go:131] duration metric: took 294.790427ms to wait for apiserver health ...
I1129 22:32:27.401822   13351 system_pods.go:43] waiting for kube-system pods to appear ...
I1129 22:32:27.558400   13351 system_pods.go:59] 5 kube-system pods found
I1129 22:32:27.558427   13351 system_pods.go:61] "etcd-minikube" [63f45099-73bb-4802-88bd-fca4438d7d27] Running
I1129 22:32:27.558456   13351 system_pods.go:61] "kube-apiserver-minikube" [327db430-17c0-4272-a3ec-f1726f3894e6] Running
I1129 22:32:27.558474   13351 system_pods.go:61] "kube-controller-manager-minikube" [179a1521-352a-4cbc-8ec8-9e0c91d29217] Running
I1129 22:32:27.558486   13351 system_pods.go:61] "kube-scheduler-minikube" [e18242c3-a910-445b-9a00-333a9cc23854] Running
I1129 22:32:27.558496   13351 system_pods.go:61] "storage-provisioner" [38eea28a-0300-43a8-a089-0b4844c7c62d] Pending
I1129 22:32:27.558506   13351 system_pods.go:74] duration metric: took 156.675196ms to wait for pod list to return data ...
I1129 22:32:27.558520   13351 kubeadm.go:581] duration metric: took 12.171621686s to wait for : map[apiserver:true system_pods:true] ...
I1129 22:32:27.558553   13351 node_conditions.go:102] verifying NodePressure condition ...
I1129 22:32:27.680997   13351 node_conditions.go:122] node storage ephemeral capacity is 65739308Ki
I1129 22:32:27.681018   13351 node_conditions.go:123] node cpu capacity is 4
I1129 22:32:27.681033   13351 node_conditions.go:105] duration metric: took 122.471069ms to run NodePressure ...
I1129 22:32:27.681055   13351 start.go:228] waiting for startup goroutines ...
I1129 22:32:28.175934   13351 kapi.go:86] Found 2 Pods for label selector app.kubernetes.io/name=ingress-nginx
I1129 22:32:28.176068   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:28.448079   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:29.146745   13351 kapi.go:86] Found 3 Pods for label selector app.kubernetes.io/name=ingress-nginx
I1129 22:32:29.146761   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:29.611037   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:29.994080   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:30.438815   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:30.961906   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:31.476364   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:31.917081   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:32.427180   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:32.936690   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:33.424884   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:33.919688   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:34.504173   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:34.947909   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:35.433530   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:35.938544   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:36.435301   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:36.924900   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:37.429945   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:37.913848   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:38.414753   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:39.008357   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:39.467548   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:39.923874   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:40.415424   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:40.939097   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:41.442431   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:41.919740   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:42.597477   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:43.045336   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:43.520183   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:44.012201   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:44.468038   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:44.980262   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:45.463815   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:45.914941   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:46.415101   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:46.935767   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:47.409848   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:47.904924   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:48.413430   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:48.923364   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:49.435734   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:49.912664   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:50.463852   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:51.005875   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:51.409839   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:51.929327   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:52.424538   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:32:52.905485   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:09.127177   13351 kapi.go:81] temporary error: getting Pods with label selector "app.kubernetes.io/name=ingress-nginx" : [etcdserver: request timed out]
I1129 22:33:28.719257   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:29.052196   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:29.155645   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:29.666095   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:30.083133   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:30.532077   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:31.243956   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:31.456157   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:31.985574   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:32.437099   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:32.961180   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:44.413577   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:50.353625   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:50.648138   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:50.996001   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:51.101796   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:51.603656   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:52.059633   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:52.491628   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:53.055352   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:53.423540   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:53.910014   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:54.416908   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:54.913921   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:55.426344   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:55.915272   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:56.409114   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:56.917432   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:57.422885   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:57.907295   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:58.401892   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:58.907060   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:59.412344   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:33:59.907531   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:00.411743   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:00.916127   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:01.408098   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:01.936930   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:02.423474   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:02.913255   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:03.407554   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:03.933272   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:04.439500   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:04.931396   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:05.409983   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:05.906127   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:06.445268   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:06.907752   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:12.330382   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:26.486503   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:26.596544   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:26.996828   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:27.449858   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:27.911688   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:28.448916   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:28.934014   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:29.412725   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:29.903434   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:30.405474   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:30.908184   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:31.400931   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:31.905255   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:32.409330   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:33.202193   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:33.401541   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:33.904736   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:35.644348   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:35.735949   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:36.673158   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:36.876330   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:43.904485   13351 kapi.go:81] temporary error: getting Pods with label selector "app.kubernetes.io/name=ingress-nginx" : [etcdserver: request timed out]
I1129 22:34:53.443611   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:53.640390   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:53.985830   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:54.456192   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:54.948969   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:55.408152   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:55.919236   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:56.425184   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:56.903538   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:57.403752   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:57.904655   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:58.405380   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:58.904872   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:59.410060   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:34:59.903569   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:00.410408   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:00.908693   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:01.407466   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:01.907122   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:02.408146   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:02.922960   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:03.413103   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:03.937496   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:04.422551   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:04.908864   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:05.412176   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:05.909101   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:06.416318   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:06.908998   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:07.415353   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:07.907886   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:08.421664   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:08.967454   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:09.412317   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:09.909091   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:10.412081   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:10.908065   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:11.411979   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:11.912172   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:12.428323   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:12.908654   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:13.715126   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:13.914465   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:15.730554   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:15.759585   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:15.924141   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:16.412392   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:16.914561   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:17.418427   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:17.910190   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:18.417171   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:18.915490   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:19.510350   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:19.917885   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:20.700516   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:20.911787   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:21.408570   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:21.909495   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:22.411786   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:22.909556   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:23.410085   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:23.905805   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:24.432553   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:24.907549   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:25.411194   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:25.905045   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:26.412802   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:26.908500   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:27.412427   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:27.903896   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:28.411398   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:28.908366   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:29.417084   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:30.558572   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:30.664005   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:30.907963   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:31.411695   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:31.906617   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:32.409808   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:32.910925   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:33.413222   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:33.905853   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:34.440942   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:35.211053   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:35.406419   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:35.907484   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:36.409457   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:36.906945   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:37.420266   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:37.906034   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:38.413006   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:38.910806   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:39.831732   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:39.906136   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:40.408319   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:40.907713   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:41.411816   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:41.935165   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:42.406421   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:42.913063   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:43.412956   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:43.908477   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:44.410430   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:44.907062   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:45.419587   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:45.907936   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:47.066173   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:47.088465   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:47.413034   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:47.905501   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:48.411817   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:48.942711   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:49.417566   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:49.911887   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:50.414336   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:50.907602   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:51.438385   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:51.907780   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:52.416666   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:52.909205   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:53.431921   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:53.909161   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:54.457353   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:54.904527   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:55.437015   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:55.902516   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:56.405585   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:56.906205   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:57.407510   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:57.903834   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:58.406929   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:58.905886   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:59.408155   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:35:59.904891   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:00.406995   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:00.904819   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:01.407560   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:01.905994   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:02.405044   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:02.905234   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:03.405902   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:03.906575   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:04.406954   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:04.905026   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:05.405392   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:05.904937   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:06.407425   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:06.907180   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:07.404458   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:07.904797   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:08.406380   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:08.905270   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:09.405036   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:09.902808   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:10.405283   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:10.908676   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:11.407728   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:11.911101   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:12.407691   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:12.905036   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:13.408248   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:13.905177   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:14.407162   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:14.908462   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:15.485534   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:15.906103   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:16.409137   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:16.906013   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:17.407545   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:17.910890   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:18.408847   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:18.909118   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:19.414812   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:19.908699   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:20.412833   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:20.903731   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:21.407563   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:21.903441   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:22.412927   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:22.918441   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:23.410967   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:23.910230   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:24.404382   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:24.905064   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:25.405974   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:25.902819   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:26.473655   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:26.905143   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:27.405409   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:27.905451   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:28.405780   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:28.903243   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:29.408297   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:29.904682   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:30.404922   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:30.904151   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:31.408457   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:31.907921   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:32.404987   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:32.905384   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:33.408934   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:33.906040   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:34.505888   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:34.901588   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:35.402179   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:35.901787   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:36.403495   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:36.902559   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:37.409908   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:37.904732   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:38.402923   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:38.906349   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:39.406897   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:39.906022   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:40.408183   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:40.906081   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:41.405739   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:41.906630   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:42.408767   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:42.904391   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:43.403258   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:43.906185   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:44.408612   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:44.907300   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:45.422563   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:45.904463   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:46.404547   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:46.904097   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:47.408720   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:47.906808   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:48.403867   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:48.908013   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:49.407833   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:49.905238   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:50.408287   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:50.909147   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:51.407078   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:51.907871   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:52.404512   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:52.905466   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:53.404906   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:53.905830   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:54.407242   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:54.908230   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:55.406198   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:55.904058   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:56.406326   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:56.910387   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:57.405028   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:57.903651   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:58.409168   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:58.906080   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:59.408527   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:36:59.908831   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:00.405676   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:00.904376   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:01.422895   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:01.904109   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:02.408481   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:02.903325   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:03.407349   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:03.907438   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:04.414553   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:04.906640   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:05.405986   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:05.906254   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:06.405441   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:06.910942   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:07.406481   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:07.906766   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:08.403878   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:08.903871   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:09.409646   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:09.904986   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:10.404720   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:10.911988   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:11.407949   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:11.904576   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:12.407465   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:12.904882   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:13.407873   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:13.905562   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:14.408531   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:14.906461   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:15.407450   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:15.905649   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:16.408198   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:16.906347   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:17.408502   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:17.901897   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:18.407906   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:18.911358   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:19.409049   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:19.905721   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:20.450056   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:20.906215   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:21.411479   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:21.909644   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:22.406184   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:22.908912   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:23.404788   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:23.902926   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:24.407809   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:24.906648   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:25.408651   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:25.904523   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:26.405852   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:26.902982   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:27.406194   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:27.905973   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:28.407058   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:28.905208   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:29.406662   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:29.904797   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:30.405787   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:30.905613   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:31.408234   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:31.904643   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:32.405158   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:32.904888   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:33.407450   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:33.907047   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:34.429280   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:34.902710   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:35.404672   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:35.911899   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:36.408066   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:36.904379   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:37.402590   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:37.906611   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:38.407339   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:38.903671   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:39.406195   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:39.904043   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:40.408196   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:40.906651   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:41.406163   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:41.907292   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:42.407486   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:42.907144   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:43.407476   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:43.908608   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:44.412877   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:44.905006   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:45.406780   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:45.906805   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:46.409303   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:46.906693   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:47.405107   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:47.911833   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:48.406681   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:48.906115   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:49.425908   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:49.905884   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:50.408227   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:50.904108   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:51.408976   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:51.903870   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:52.406749   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:52.904398   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:53.409480   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:53.903590   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:54.411681   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:54.904508   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:55.406680   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:55.904475   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:56.405894   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:56.904755   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:57.406454   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:57.903699   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:58.406629   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:58.903464   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:59.406035   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:37:59.904628   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:00.408302   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:00.904016   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:01.407886   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:01.907419   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:02.404674   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:02.903909   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:03.406572   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:03.904666   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:04.411789   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:04.902077   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:05.402614   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:05.903282   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:06.404960   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:06.902457   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:07.405141   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:07.923920   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:08.407618   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:08.904985   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:09.409656   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:09.960860   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:10.407117   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:10.903380   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:11.406038   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:11.904744   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:12.405598   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:12.905608   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:13.405955   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:13.906809   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:14.412470   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:14.905968   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:15.405990   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:15.909820   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:16.405361   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:16.906080   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:17.405262   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:17.903479   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:18.407265   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:18.905643   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:19.406574   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:19.905926   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:20.405464   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:20.904666   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:21.409057   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:21.907804   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:22.406078   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:22.902754   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:23.405539   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:23.904629   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:24.472853   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:24.904485   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:25.404180   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:25.913093   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:26.406426   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:26.905352   13351 kapi.go:96] waiting for pod "app.kubernetes.io/name=ingress-nginx", current state: Pending: [<nil>]
I1129 22:38:27.201785   13351 kapi.go:107] duration metric: took 6m0.000888704s to wait for app.kubernetes.io/name=ingress-nginx ...
W1129 22:38:27.203345   13351 out.go:239] ‚ùó  Enabling 'ingress' returned an error: running callbacks: [waiting for app.kubernetes.io/name=ingress-nginx pods: context deadline exceeded]
I1129 22:38:27.217425   13351 out.go:177] üåü  Enabled addons: storage-provisioner, dashboard, default-storageclass
I1129 22:38:27.323719   13351 addons.go:502] enable addons completed in 6m12.102483774s: enabled=[storage-provisioner dashboard default-storageclass]
I1129 22:38:27.323865   13351 start.go:233] waiting for cluster config update ...
I1129 22:38:27.323912   13351 start.go:242] writing updated cluster config ...
I1129 22:38:27.326187   13351 ssh_runner.go:195] Run: rm -f paused
I1129 22:38:30.896645   13351 start.go:600] kubectl: 1.28.4, cluster: 1.27.3 (minor skew: 1)
I1129 22:38:30.905473   13351 out.go:177] üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* Nov 29 16:01:21 minikube dockerd[514]: time="2023-11-29T16:01:21.725151682Z" level=info msg="Daemon shutdown complete"
Nov 29 16:01:21 minikube systemd[1]: docker.service: Deactivated successfully.
Nov 29 16:01:21 minikube systemd[1]: Stopped Docker Application Container Engine.
Nov 29 16:01:21 minikube systemd[1]: Starting Docker Application Container Engine...
Nov 29 16:01:21 minikube dockerd[725]: time="2023-11-29T16:01:21.828896159Z" level=info msg="Starting up"
Nov 29 16:01:21 minikube dockerd[725]: time="2023-11-29T16:01:21.885996708Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Nov 29 16:01:21 minikube dockerd[725]: time="2023-11-29T16:01:21.949224388Z" level=info msg="Loading containers: start."
Nov 29 16:01:22 minikube dockerd[725]: time="2023-11-29T16:01:22.355501858Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Nov 29 16:01:22 minikube dockerd[725]: time="2023-11-29T16:01:22.463804275Z" level=info msg="Loading containers: done."
Nov 29 16:01:22 minikube dockerd[725]: time="2023-11-29T16:01:22.498756690Z" level=info msg="Docker daemon" commit=4ffc614 graphdriver=overlay2 version=24.0.4
Nov 29 16:01:22 minikube dockerd[725]: time="2023-11-29T16:01:22.498942524Z" level=info msg="Daemon has completed initialization"
Nov 29 16:01:22 minikube dockerd[725]: time="2023-11-29T16:01:22.664843696Z" level=info msg="API listen on /var/run/docker.sock"
Nov 29 16:01:22 minikube dockerd[725]: time="2023-11-29T16:01:22.665151036Z" level=info msg="API listen on [::]:2376"
Nov 29 16:01:22 minikube systemd[1]: Started Docker Application Container Engine.
Nov 29 16:01:23 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Start docker client with request timeout 0s"
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Hairpin mode is set to hairpin-veth"
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Loaded network plugin cni"
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Docker cri networking managed by network plugin cni"
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Docker Info: &{ID:378202f1-88b8-442f-a472-9c49143841b2 Containers:10 ContainersRunning:0 ContainersPaused:0 ContainersStopped:10 Images:8 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:24 OomKillDisable:false NGoroutines:36 SystemTime:2023-11-29T16:01:24.273481846Z LoggingDriver:json-file CgroupDriver:systemd CgroupVersion:2 NEventsListener:0 KernelVersion:6.4.16-linuxkit OperatingSystem:Ubuntu 22.04.2 LTS OSVersion:22.04 OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc0005a21c0 NCPU:4 MemTotal:1974509568 GenericResources:[] DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy:control-plane.minikube.internal Name:minikube Labels:[provider=docker] ExperimentalBuild:false ServerVersion:24.0.4 ClusterStore: ClusterAdvertise: Runtimes:map[io.containerd.runc.v2:{Path:runc Args:[] Shim:<nil>} runc:{Path:runc Args:[] Shim:<nil>}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:<nil> Warnings:[]} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:3dce8eb055cbb6872793272b4f20ed16117344f8 Expected:3dce8eb055cbb6872793272b4f20ed16117344f8} RuncCommit:{ID:v1.1.7-0-g860f061 Expected:v1.1.7-0-g860f061} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=builtin name=cgroupns] ProductLicense: DefaultAddressPools:[] Warnings:[]}"
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Setting cgroupDriver systemd"
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Nov 29 16:01:24 minikube cri-dockerd[953]: time="2023-11-29T16:01:24Z" level=info msg="Start cri-dockerd grpc backend"
Nov 29 16:01:24 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Nov 29 16:01:59 minikube cri-dockerd[953]: time="2023-11-29T16:01:59Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/7dc782215702109df4bf2e19fac843622c0d291af3e7fcc166fbfeec0f47beec/resolv.conf as [nameserver 192.168.65.2 options ndots:0]"
Nov 29 16:01:59 minikube cri-dockerd[953]: time="2023-11-29T16:01:59Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/90ce909b180addf0535898ebda3906491d7c91fb17fb8bc107e2dc0f1499bec7/resolv.conf as [nameserver 192.168.65.2 options ndots:0]"
Nov 29 16:01:59 minikube cri-dockerd[953]: time="2023-11-29T16:01:59Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/378719ba96ef572f940cae11ac54d1fe6a8ffb2a57e1a71dcf7ab70d7e4a212e/resolv.conf as [nameserver 192.168.65.2 options ndots:0]"
Nov 29 16:01:59 minikube cri-dockerd[953]: time="2023-11-29T16:01:59Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/c5fad8174262097699d49485c61ff255bf6698c429bce42a66b49183055807b0/resolv.conf as [nameserver 192.168.65.2 options ndots:0]"
Nov 29 16:02:12 minikube cri-dockerd[953]: time="2023-11-29T16:02:12Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:10.244.0.0/24,},}"
Nov 29 16:02:36 minikube cri-dockerd[953]: time="2023-11-29T16:02:36Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/2c1c047fd6837098d340fd3759cd73463f03299808a7a599d37abc5490af4478/resolv.conf as [nameserver 192.168.65.2 options ndots:0]"
Nov 29 16:02:36 minikube cri-dockerd[953]: time="2023-11-29T16:02:36Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/52b2b159f5131eaf5b72aa30bf8592e52409a4a851a86f5c5f3963e0308069f6/resolv.conf as [nameserver 192.168.65.2 options ndots:0]"
Nov 29 16:02:40 minikube cri-dockerd[953]: time="2023-11-29T16:02:40Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/bec1bf5ed3c6700f387144a64f239aebba8b4217bc5d7a01d9a58c2073c5c7f3/resolv.conf as [nameserver 192.168.65.2 options ndots:0]"
Nov 29 16:02:40 minikube cri-dockerd[953]: time="2023-11-29T16:02:40Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/6eb639b6aee83f1379b5e80c41430fbdc7b7727611209c2125868bba31198c4b/resolv.conf as [nameserver 10.96.0.10 search kubernetes-dashboard.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Nov 29 16:02:40 minikube cri-dockerd[953]: time="2023-11-29T16:02:40Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/2f316fe80c8dc0b2db7087e2c756be6d424368ce2d07923cef6d0a1860f1e2a7/resolv.conf as [nameserver 10.96.0.10 search kubernetes-dashboard.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Nov 29 16:02:45 minikube dockerd[725]: time="2023-11-29T16:02:45.834123776Z" level=warning msg="reference for unknown type: " digest="sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c" remote="docker.io/kubernetesui/metrics-scraper@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c"
Nov 29 16:02:58 minikube cri-dockerd[953]: time="2023-11-29T16:02:58Z" level=info msg="Pulling image docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c: 978be80e3ee3: Download complete "
Nov 29 16:03:09 minikube cri-dockerd[953]: time="2023-11-29T16:03:09Z" level=info msg="Pulling image docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c: 978be80e3ee3: Extracting [==================================================>]  19.74MB/19.74MB"
Nov 29 16:03:17 minikube dockerd[725]: time="2023-11-29T16:03:17.591357515Z" level=info msg="ignoring event" container=560c03dac6e3746debc4487c37ab9b6b7b25668e3c4c0171ba95584a55c31bd5 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 29 16:03:18 minikube cri-dockerd[953]: time="2023-11-29T16:03:18Z" level=info msg="Pulling image docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c: 978be80e3ee3: Extracting [==================================================>]  19.74MB/19.74MB"
Nov 29 16:03:28 minikube cri-dockerd[953]: time="2023-11-29T16:03:28Z" level=info msg="Pulling image docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c: 5866d2c04d96: Extracting [==================================================>]     530B/530B"
Nov 29 16:03:30 minikube cri-dockerd[953]: time="2023-11-29T16:03:30Z" level=info msg="Stop pulling image docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c: Status: Downloaded newer image for kubernetesui/metrics-scraper@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c"
Nov 29 16:03:32 minikube dockerd[725]: time="2023-11-29T16:03:32.088574977Z" level=warning msg="reference for unknown type: " digest="sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93" remote="docker.io/kubernetesui/dashboard@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93"
Nov 29 16:03:59 minikube cri-dockerd[953]: time="2023-11-29T16:03:59Z" level=info msg="Pulling image docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93: ee3247c7e545: Downloading [==============>                                    ]  21.46MB/75.78MB"
Nov 29 16:04:09 minikube cri-dockerd[953]: time="2023-11-29T16:04:09Z" level=info msg="Pulling image docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93: ee3247c7e545: Downloading [===============================>                   ]  48.21MB/75.78MB"
Nov 29 16:04:19 minikube cri-dockerd[953]: time="2023-11-29T16:04:19Z" level=info msg="Pulling image docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93: ee3247c7e545: Downloading [===============================================>   ]  71.79MB/75.78MB"
Nov 29 16:04:25 minikube dockerd[725]: time="2023-11-29T16:04:25.481427825Z" level=info msg="ignoring event" container=5b035af680154ae2eafcf5e70a4dc467431f40431facbe841bf5597f631a5860 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 29 16:04:29 minikube cri-dockerd[953]: time="2023-11-29T16:04:29Z" level=info msg="Pulling image docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93: ee3247c7e545: Extracting [=======================>                           ]  35.65MB/75.78MB"
Nov 29 16:04:39 minikube cri-dockerd[953]: time="2023-11-29T16:04:39Z" level=info msg="Pulling image docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93: ee3247c7e545: Extracting [========================================>          ]  60.72MB/75.78MB"
Nov 29 16:04:49 minikube cri-dockerd[953]: time="2023-11-29T16:04:49Z" level=info msg="Pulling image docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93: ee3247c7e545: Extracting [==================================================>]  75.78MB/75.78MB"
Nov 29 16:04:54 minikube cri-dockerd[953]: time="2023-11-29T16:04:54Z" level=info msg="Stop pulling image docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93: Status: Downloaded newer image for kubernetesui/dashboard@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93"
Nov 29 16:10:50 minikube dockerd[725]: time="2023-11-29T16:10:50.700845018Z" level=warning msg="no trace recorder found, skipping"
Nov 29 16:10:55 minikube cri-dockerd[953]: time="2023-11-29T16:10:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/93bffe3dc2fc91ac2b90fcb9b5c7a8e4e57aa9d2fd0e7b1aebeb30830ab1cb39/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Nov 29 16:11:15 minikube dockerd[725]: time="2023-11-29T16:11:15.753678721Z" level=info msg="ignoring event" container=663c94037b00b34e0993dfcb71033495fe6221f9fac36bfcbe861f2d3a0ac413 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 29 16:11:19 minikube dockerd[725]: time="2023-11-29T16:11:19.619930051Z" level=error msg="Failed to compute size of container rootfs 5b035af680154ae2eafcf5e70a4dc467431f40431facbe841bf5597f631a5860: mount does not exist"
Nov 29 16:11:29 minikube dockerd[725]: time="2023-11-29T16:11:29.127100276Z" level=info msg="Container failed to exit within 30s of signal 15 - using the force" container=a0badaa27694fb3448cedceff4973951db667a27d250ec78e7420d1110661373
Nov 29 16:11:29 minikube dockerd[725]: time="2023-11-29T16:11:29.427241264Z" level=info msg="ignoring event" container=a0badaa27694fb3448cedceff4973951db667a27d250ec78e7420d1110661373 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 29 16:11:29 minikube cri-dockerd[953]: time="2023-11-29T16:11:29Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"auth-depl-774f794f7-2wvfn_default\": unexpected command output Device \"eth0\" does not exist.\n with error: exit status 1"
Nov 29 16:11:30 minikube dockerd[725]: time="2023-11-29T16:11:30.006751400Z" level=info msg="ignoring event" container=93bffe3dc2fc91ac2b90fcb9b5c7a8e4e57aa9d2fd0e7b1aebeb30830ab1cb39 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                                                  CREATED             STATE               NAME                        ATTEMPT             POD ID              POD
a1aa3e544b1cd       6e38f40d628db                                                                                          20 minutes ago      Running             storage-provisioner         3                   2c1c047fd6837       storage-provisioner
158a771c2b8d7       kubernetesui/dashboard@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93         27 minutes ago      Running             kubernetes-dashboard        0                   2f316fe80c8dc       kubernetes-dashboard-5c5cfc8747-xjv27
861918d2f1dea       kubernetesui/metrics-scraper@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c   28 minutes ago      Running             dashboard-metrics-scraper   0                   6eb639b6aee83       dashboard-metrics-scraper-5dd9cbfd69-5h8sc
e4fab3b62d510       ead0a4a53df89                                                                                          29 minutes ago      Running             coredns                     0                   bec1bf5ed3c67       coredns-5d78c9869d-cqtwj
268a1af1e0bcf       5780543258cf0                                                                                          29 minutes ago      Running             kube-proxy                  0                   52b2b159f5131       kube-proxy-ttsg8
9372752612d5d       08a0c939e61b7                                                                                          30 minutes ago      Running             kube-apiserver              2                   378719ba96ef5       kube-apiserver-minikube
feff91b77d87d       7cffc01dba0e1                                                                                          30 minutes ago      Running             kube-controller-manager     4                   90ce909b180ad       kube-controller-manager-minikube
d6ea74aebb4d0       41697ceeb70b3                                                                                          30 minutes ago      Running             kube-scheduler              1                   c5fad81742620       kube-scheduler-minikube
555a61018201e       86b6af7dd652c                                                                                          30 minutes ago      Running             etcd                        1                   7dc7822157021       etcd-minikube
5d494ce9fe5d6       7cffc01dba0e1                                                                                          24 hours ago        Exited              kube-controller-manager     3                   f32fae356c218       kube-controller-manager-minikube
f5d3dac36390e       08a0c939e61b7                                                                                          24 hours ago        Exited              kube-apiserver              1                   b1bfe67fba6e2       kube-apiserver-minikube
8ab073a12072b       41697ceeb70b3                                                                                          24 hours ago        Exited              kube-scheduler              0                   24127f25fe1a2       kube-scheduler-minikube
fabfae8af6abc       86b6af7dd652c                                                                                          24 hours ago        Exited              etcd                        0                   d714f7b478cf1       etcd-minikube

* 
* ==> coredns [e4fab3b62d51] <==
* [INFO] plugin/ready: Still waiting on: "kubernetes"
.:53
[INFO] plugin/reload: Running configuration SHA512 = 75e5db48a73272e2c90919c8256e5cca0293ae0ed689e2ed44f1254a9589c3d004cb3e693d059116718c47e9305987b828b11b2735a1cefa59e4a9489dda5cee
CoreDNS-1.10.1
linux/amd64, go1.20, 055b2c3
[INFO] 127.0.0.1:44702 - 27695 "HINFO IN 5097075726031714642.4414750587382477249. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.024052755s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              <none>
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
Annotations:        node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Tue, 28 Nov 2023 16:39:51 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Wed, 29 Nov 2023 16:31:58 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 29 Nov 2023 16:31:54 +0000   Wed, 29 Nov 2023 16:03:38 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 29 Nov 2023 16:31:54 +0000   Wed, 29 Nov 2023 16:03:38 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 29 Nov 2023 16:31:54 +0000   Wed, 29 Nov 2023 16:03:38 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 29 Nov 2023 16:31:54 +0000   Wed, 29 Nov 2023 16:03:38 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.58.2
  Hostname:    minikube
Capacity:
  cpu:                4
  ephemeral-storage:  65739308Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             1928232Ki
  pods:               110
Allocatable:
  cpu:                4
  ephemeral-storage:  65739308Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             1928232Ki
  pods:               110
System Info:
  Machine ID:                 6cd86347f98e40bf8fd29347f7cc178a
  System UUID:                6cd86347f98e40bf8fd29347f7cc178a
  Boot ID:                    4c9a4f31-978c-45f2-9237-fd74a4a3376a
  Kernel Version:             6.4.16-linuxkit
  OS Image:                   Ubuntu 22.04.2 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://24.0.4
  Kubelet Version:            v1.27.3
  Kube-Proxy Version:         v1.27.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (9 in total)
  Namespace                   Name                                          CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                          ------------  ----------  ---------------  -------------  ---
  kube-system                 coredns-5d78c9869d-cqtwj                      100m (2%!)(MISSING)     0 (0%!)(MISSING)      70Mi (3%!)(MISSING)        170Mi (9%!)(MISSING)     29m
  kube-system                 etcd-minikube                                 100m (2%!)(MISSING)     0 (0%!)(MISSING)      100Mi (5%!)(MISSING)       0 (0%!)(MISSING)         23h
  kube-system                 kube-apiserver-minikube                       250m (6%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         23h
  kube-system                 kube-controller-manager-minikube              200m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         23h
  kube-system                 kube-proxy-ttsg8                              0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         29m
  kube-system                 kube-scheduler-minikube                       100m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         23h
  kube-system                 storage-provisioner                           0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         29m
  kubernetes-dashboard        dashboard-metrics-scraper-5dd9cbfd69-5h8sc    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         29m
  kubernetes-dashboard        kubernetes-dashboard-5c5cfc8747-xjv27         0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         29m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                750m (18%!)(MISSING)  0 (0%!)(MISSING)
  memory             170Mi (9%!)(MISSING)  170Mi (9%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                From             Message
  ----    ------                   ----               ----             -------
  Normal  Starting                 29m                kube-proxy       
  Normal  NodeAllocatableEnforced  23h                kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  23h (x8 over 23h)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    23h (x8 over 23h)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     23h (x7 over 23h)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  RegisteredNode           23h                node-controller  Node minikube event: Registered Node minikube in Controller
  Normal  Starting                 30m                kubelet          Starting kubelet.
  Normal  NodeHasSufficientMemory  30m (x8 over 30m)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    30m (x8 over 30m)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     30m (x7 over 30m)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeAllocatableEnforced  30m                kubelet          Updated Node Allocatable limit across pods
  Normal  RegisteredNode           29m                node-controller  Node minikube event: Registered Node minikube in Controller
  Normal  NodeNotReady             28m                node-controller  Node minikube status is now: NodeNotReady

* 
* ==> dmesg <==
* [Nov29 16:00] Hangcheck: starting hangcheck timer 0.9.1 (tick is 180 seconds, margin is 60 seconds).
[  +0.048967] device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
[  +0.315023] FAT-fs (vdb): utf8 is not a recommended IO charset for FAT filesystems, filesystem will be case sensitive!
[  +0.000221] FAT-fs (vdb): utf8 is not a recommended IO charset for FAT filesystems, filesystem will be case sensitive!
[  +0.378932] netlink: 'init': attribute type 4 has an invalid length.
[  +3.275268] grpcfuse: loading out-of-tree module taints kernel.
[Nov29 16:01] systemd[1125]: memfd_create() called without MFD_EXEC or MFD_NOEXEC_SEAL set
[Nov29 16:02] hrtimer: interrupt took 2724525 ns

* 
* ==> etcd [555a61018201] <==
* {"level":"warn","ts":"2023-11-29T16:28:54.217Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-29T16:28:53.914Z","time spent":"302.640596ms","remote":"127.0.0.1:50168","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":832,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/events/ingress-nginx/ingress-nginx-controller-5df97545c4-bqphk.179c2376094fb265\" mod_revision:2304 > success:<request_put:<key:\"/registry/events/ingress-nginx/ingress-nginx-controller-5df97545c4-bqphk.179c2376094fb265\" value_size:725 lease:3238523658152271721 >> failure:<request_range:<key:\"/registry/events/ingress-nginx/ingress-nginx-controller-5df97545c4-bqphk.179c2376094fb265\" > >"}
{"level":"info","ts":"2023-11-29T16:29:01.458Z","caller":"traceutil/trace.go:171","msg":"trace[468425868] transaction","detail":"{read_only:false; response_revision:2549; number_of_response:1; }","duration":"289.908739ms","start":"2023-11-29T16:29:01.168Z","end":"2023-11-29T16:29:01.458Z","steps":["trace[468425868] 'process raft request'  (duration: 289.451402ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:29:04.063Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"385.207638ms","expected-duration":"100ms","prefix":"","request":"header:<ID:3238523658152271768 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:2549 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:512 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >>","response":"size:16"}
{"level":"info","ts":"2023-11-29T16:29:04.064Z","caller":"traceutil/trace.go:171","msg":"trace[206043048] linearizableReadLoop","detail":"{readStateIndex:3382; appliedIndex:3381; }","duration":"186.987142ms","start":"2023-11-29T16:29:03.877Z","end":"2023-11-29T16:29:04.064Z","steps":["trace[206043048] 'read index received'  (duration: 65.654¬µs)","trace[206043048] 'applied index is now lower than readState.Index'  (duration: 186.601585ms)"],"step_count":2}
{"level":"info","ts":"2023-11-29T16:29:04.066Z","caller":"traceutil/trace.go:171","msg":"trace[1992092701] transaction","detail":"{read_only:false; response_revision:2552; number_of_response:1; }","duration":"590.421402ms","start":"2023-11-29T16:29:03.475Z","end":"2023-11-29T16:29:04.066Z","steps":["trace[1992092701] 'process raft request'  (duration: 199.693677ms)","trace[1992092701] 'compare'  (duration: 384.769182ms)"],"step_count":2}
{"level":"warn","ts":"2023-11-29T16:29:04.066Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-29T16:29:03.475Z","time spent":"590.705266ms","remote":"127.0.0.1:50256","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":585,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:2549 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:512 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >"}
{"level":"warn","ts":"2023-11-29T16:29:04.067Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"189.886585ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-11-29T16:29:04.067Z","caller":"traceutil/trace.go:171","msg":"trace[1671541330] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:2552; }","duration":"190.124894ms","start":"2023-11-29T16:29:03.877Z","end":"2023-11-29T16:29:04.067Z","steps":["trace[1671541330] 'agreement among raft nodes before linearized reading'  (duration: 187.236223ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:29:04.917Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"632.605176ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/daemonsets/\" range_end:\"/registry/daemonsets0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2023-11-29T16:29:04.918Z","caller":"traceutil/trace.go:171","msg":"trace[678272977] range","detail":"{range_begin:/registry/daemonsets/; range_end:/registry/daemonsets0; response_count:0; response_revision:2552; }","duration":"632.747429ms","start":"2023-11-29T16:29:04.285Z","end":"2023-11-29T16:29:04.918Z","steps":["trace[678272977] 'count revisions from in-memory index tree'  (duration: 632.210934ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:29:04.918Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-29T16:29:04.285Z","time spent":"632.865886ms","remote":"127.0.0.1:50542","response type":"/etcdserverpb.KV/Range","request count":0,"request size":48,"response count":1,"response size":30,"request content":"key:\"/registry/daemonsets/\" range_end:\"/registry/daemonsets0\" count_only:true "}
{"level":"warn","ts":"2023-11-29T16:29:04.920Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"662.73483ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kubernetes-dashboard/dashboard-metrics-scraper\" ","response":"range_response_count:1 size:887"}
{"level":"info","ts":"2023-11-29T16:29:04.920Z","caller":"traceutil/trace.go:171","msg":"trace[775564235] range","detail":"{range_begin:/registry/services/endpoints/kubernetes-dashboard/dashboard-metrics-scraper; range_end:; response_count:1; response_revision:2552; }","duration":"663.853514ms","start":"2023-11-29T16:29:04.256Z","end":"2023-11-29T16:29:04.920Z","steps":["trace[775564235] 'range keys from in-memory index tree'  (duration: 660.908099ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:29:04.920Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-29T16:29:04.256Z","time spent":"663.995387ms","remote":"127.0.0.1:50256","response type":"/etcdserverpb.KV/Range","request count":0,"request size":77,"response count":1,"response size":910,"request content":"key:\"/registry/services/endpoints/kubernetes-dashboard/dashboard-metrics-scraper\" "}
{"level":"info","ts":"2023-11-29T16:29:06.212Z","caller":"traceutil/trace.go:171","msg":"trace[69123331] transaction","detail":"{read_only:false; response_revision:2553; number_of_response:1; }","duration":"128.416483ms","start":"2023-11-29T16:29:06.083Z","end":"2023-11-29T16:29:06.212Z","steps":["trace[69123331] 'process raft request'  (duration: 128.06753ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:29:08.430Z","caller":"traceutil/trace.go:171","msg":"trace[387923097] transaction","detail":"{read_only:false; response_revision:2554; number_of_response:1; }","duration":"200.387516ms","start":"2023-11-29T16:29:08.230Z","end":"2023-11-29T16:29:08.430Z","steps":["trace[387923097] 'process raft request'  (duration: 200.136017ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:29:13.816Z","caller":"traceutil/trace.go:171","msg":"trace[790729995] transaction","detail":"{read_only:false; response_revision:2559; number_of_response:1; }","duration":"344.400391ms","start":"2023-11-29T16:29:13.471Z","end":"2023-11-29T16:29:13.815Z","steps":["trace[790729995] 'process raft request'  (duration: 336.379422ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:29:13.816Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-29T16:29:13.471Z","time spent":"344.589854ms","remote":"127.0.0.1:50384","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":521,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/leases/kube-node-lease/minikube\" mod_revision:2551 > success:<request_put:<key:\"/registry/leases/kube-node-lease/minikube\" value_size:472 >> failure:<request_range:<key:\"/registry/leases/kube-node-lease/minikube\" > >"}
{"level":"info","ts":"2023-11-29T16:29:34.598Z","caller":"traceutil/trace.go:171","msg":"trace[2084418377] transaction","detail":"{read_only:false; response_revision:2575; number_of_response:1; }","duration":"109.408938ms","start":"2023-11-29T16:29:34.489Z","end":"2023-11-29T16:29:34.598Z","steps":["trace[2084418377] 'process raft request'  (duration: 109.185531ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:29:35.123Z","caller":"traceutil/trace.go:171","msg":"trace[1476039056] transaction","detail":"{read_only:false; response_revision:2576; number_of_response:1; }","duration":"105.365418ms","start":"2023-11-29T16:29:35.018Z","end":"2023-11-29T16:29:35.123Z","steps":["trace[1476039056] 'process raft request'  (duration: 105.006781ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:29:37.246Z","caller":"traceutil/trace.go:171","msg":"trace[801678926] transaction","detail":"{read_only:false; response_revision:2577; number_of_response:1; }","duration":"109.335217ms","start":"2023-11-29T16:29:37.136Z","end":"2023-11-29T16:29:37.246Z","steps":["trace[801678926] 'process raft request'  (duration: 109.087311ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:29:41.461Z","caller":"traceutil/trace.go:171","msg":"trace[361735875] linearizableReadLoop","detail":"{readStateIndex:3418; appliedIndex:3417; }","duration":"145.829086ms","start":"2023-11-29T16:29:41.315Z","end":"2023-11-29T16:29:41.461Z","steps":["trace[361735875] 'read index received'  (duration: 145.662665ms)","trace[361735875] 'applied index is now lower than readState.Index'  (duration: 164.372¬µs)"],"step_count":2}
{"level":"warn","ts":"2023-11-29T16:29:41.461Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"146.098951ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/persistentvolumes/\" range_end:\"/registry/persistentvolumes0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-11-29T16:29:41.461Z","caller":"traceutil/trace.go:171","msg":"trace[2133971579] range","detail":"{range_begin:/registry/persistentvolumes/; range_end:/registry/persistentvolumes0; response_count:0; response_revision:2580; }","duration":"146.224864ms","start":"2023-11-29T16:29:41.315Z","end":"2023-11-29T16:29:41.461Z","steps":["trace[2133971579] 'agreement among raft nodes before linearized reading'  (duration: 145.992026ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:29:41.461Z","caller":"traceutil/trace.go:171","msg":"trace[775305206] transaction","detail":"{read_only:false; response_revision:2580; number_of_response:1; }","duration":"178.375128ms","start":"2023-11-29T16:29:41.283Z","end":"2023-11-29T16:29:41.461Z","steps":["trace[775305206] 'process raft request'  (duration: 177.851395ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:29:45.663Z","caller":"traceutil/trace.go:171","msg":"trace[1209358972] transaction","detail":"{read_only:false; response_revision:2584; number_of_response:1; }","duration":"157.311769ms","start":"2023-11-29T16:29:45.506Z","end":"2023-11-29T16:29:45.663Z","steps":["trace[1209358972] 'process raft request'  (duration: 156.988036ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:29:53.989Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"111.415843ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-11-29T16:29:53.989Z","caller":"traceutil/trace.go:171","msg":"trace[1702737911] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:2589; }","duration":"111.613217ms","start":"2023-11-29T16:29:53.877Z","end":"2023-11-29T16:29:53.989Z","steps":["trace[1702737911] 'range keys from in-memory index tree'  (duration: 111.057193ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:29:54.130Z","caller":"traceutil/trace.go:171","msg":"trace[1369690710] transaction","detail":"{read_only:false; response_revision:2590; number_of_response:1; }","duration":"105.533189ms","start":"2023-11-29T16:29:54.024Z","end":"2023-11-29T16:29:54.130Z","steps":["trace[1369690710] 'process raft request'  (duration: 105.104202ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:29:55.157Z","caller":"traceutil/trace.go:171","msg":"trace[1732313118] transaction","detail":"{read_only:false; response_revision:2591; number_of_response:1; }","duration":"163.927125ms","start":"2023-11-29T16:29:54.993Z","end":"2023-11-29T16:29:55.157Z","steps":["trace[1732313118] 'process raft request'  (duration: 163.504035ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:00.166Z","caller":"traceutil/trace.go:171","msg":"trace[232274142] transaction","detail":"{read_only:false; response_revision:2595; number_of_response:1; }","duration":"257.078408ms","start":"2023-11-29T16:29:59.909Z","end":"2023-11-29T16:30:00.166Z","steps":["trace[232274142] 'process raft request'  (duration: 256.812358ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:06.357Z","caller":"traceutil/trace.go:171","msg":"trace[1589814176] transaction","detail":"{read_only:false; response_revision:2600; number_of_response:1; }","duration":"129.262044ms","start":"2023-11-29T16:30:06.227Z","end":"2023-11-29T16:30:06.357Z","steps":["trace[1589814176] 'process raft request'  (duration: 128.980112ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:10.587Z","caller":"traceutil/trace.go:171","msg":"trace[1607025253] transaction","detail":"{read_only:false; response_revision:2603; number_of_response:1; }","duration":"192.505306ms","start":"2023-11-29T16:30:10.395Z","end":"2023-11-29T16:30:10.587Z","steps":["trace[1607025253] 'process raft request'  (duration: 192.317691ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:14.664Z","caller":"traceutil/trace.go:171","msg":"trace[765362393] transaction","detail":"{read_only:false; response_revision:2605; number_of_response:1; }","duration":"251.554724ms","start":"2023-11-29T16:30:14.412Z","end":"2023-11-29T16:30:14.664Z","steps":["trace[765362393] 'process raft request'  (duration: 250.61515ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:18.838Z","caller":"traceutil/trace.go:171","msg":"trace[749102136] transaction","detail":"{read_only:false; response_revision:2609; number_of_response:1; }","duration":"106.531875ms","start":"2023-11-29T16:30:18.731Z","end":"2023-11-29T16:30:18.838Z","steps":["trace[749102136] 'process raft request'  (duration: 106.315295ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:19.404Z","caller":"traceutil/trace.go:171","msg":"trace[657567029] transaction","detail":"{read_only:false; response_revision:2610; number_of_response:1; }","duration":"199.049558ms","start":"2023-11-29T16:30:19.204Z","end":"2023-11-29T16:30:19.403Z","steps":["trace[657567029] 'process raft request'  (duration: 194.613946ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:33.101Z","caller":"traceutil/trace.go:171","msg":"trace[116510389] transaction","detail":"{read_only:false; response_revision:2620; number_of_response:1; }","duration":"117.756832ms","start":"2023-11-29T16:30:32.983Z","end":"2023-11-29T16:30:33.101Z","steps":["trace[116510389] 'process raft request'  (duration: 117.588062ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:39.319Z","caller":"traceutil/trace.go:171","msg":"trace[1837431698] transaction","detail":"{read_only:false; response_revision:2625; number_of_response:1; }","duration":"114.69696ms","start":"2023-11-29T16:30:39.204Z","end":"2023-11-29T16:30:39.319Z","steps":["trace[1837431698] 'process raft request'  (duration: 110.200424ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:45.702Z","caller":"traceutil/trace.go:171","msg":"trace[1272544496] transaction","detail":"{read_only:false; response_revision:2630; number_of_response:1; }","duration":"125.226735ms","start":"2023-11-29T16:30:45.577Z","end":"2023-11-29T16:30:45.702Z","steps":["trace[1272544496] 'process raft request'  (duration: 124.552966ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:30:45.950Z","caller":"traceutil/trace.go:171","msg":"trace[632205564] transaction","detail":"{read_only:false; response_revision:2631; number_of_response:1; }","duration":"126.900373ms","start":"2023-11-29T16:30:45.823Z","end":"2023-11-29T16:30:45.950Z","steps":["trace[632205564] 'process raft request'  (duration: 105.476794ms)","trace[632205564] 'compare'  (duration: 20.060838ms)"],"step_count":2}
{"level":"info","ts":"2023-11-29T16:30:56.048Z","caller":"traceutil/trace.go:171","msg":"trace[1881281314] transaction","detail":"{read_only:false; response_revision:2638; number_of_response:1; }","duration":"100.838265ms","start":"2023-11-29T16:30:55.947Z","end":"2023-11-29T16:30:56.048Z","steps":["trace[1881281314] 'process raft request'  (duration: 99.838407ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:31:28.687Z","caller":"traceutil/trace.go:171","msg":"trace[315268924] transaction","detail":"{read_only:false; response_revision:2664; number_of_response:1; }","duration":"108.723642ms","start":"2023-11-29T16:31:28.578Z","end":"2023-11-29T16:31:28.687Z","steps":["trace[315268924] 'process raft request'  (duration: 108.494831ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:31:30.831Z","caller":"traceutil/trace.go:171","msg":"trace[1900533719] transaction","detail":"{read_only:false; response_revision:2666; number_of_response:1; }","duration":"122.712655ms","start":"2023-11-29T16:31:30.708Z","end":"2023-11-29T16:31:30.831Z","steps":["trace[1900533719] 'process raft request'  (duration: 122.198645ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:31:36.795Z","caller":"traceutil/trace.go:171","msg":"trace[877389030] transaction","detail":"{read_only:false; response_revision:2669; number_of_response:1; }","duration":"388.623169ms","start":"2023-11-29T16:31:36.406Z","end":"2023-11-29T16:31:36.795Z","steps":["trace[877389030] 'process raft request'  (duration: 388.407221ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:31:36.795Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-29T16:31:36.406Z","time spent":"388.865111ms","remote":"127.0.0.1:50384","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":673,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" mod_revision:2661 > success:<request_put:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" value_size:600 >> failure:<request_range:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" > >"}
{"level":"info","ts":"2023-11-29T16:31:37.905Z","caller":"traceutil/trace.go:171","msg":"trace[428116302] transaction","detail":"{read_only:false; response_revision:2671; number_of_response:1; }","duration":"114.69425ms","start":"2023-11-29T16:31:37.790Z","end":"2023-11-29T16:31:37.905Z","steps":["trace[428116302] 'process raft request'  (duration: 114.489272ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:31:41.288Z","caller":"traceutil/trace.go:171","msg":"trace[1930686827] transaction","detail":"{read_only:false; response_revision:2674; number_of_response:1; }","duration":"176.235655ms","start":"2023-11-29T16:31:41.112Z","end":"2023-11-29T16:31:41.288Z","steps":["trace[1930686827] 'process raft request'  (duration: 176.00285ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:31:55.402Z","caller":"traceutil/trace.go:171","msg":"trace[1416425295] linearizableReadLoop","detail":"{readStateIndex:3549; appliedIndex:3547; }","duration":"514.057209ms","start":"2023-11-29T16:31:54.888Z","end":"2023-11-29T16:31:55.402Z","steps":["trace[1416425295] 'read index received'  (duration: 209.008817ms)","trace[1416425295] 'applied index is now lower than readState.Index'  (duration: 305.04679ms)"],"step_count":2}
{"level":"info","ts":"2023-11-29T16:31:55.402Z","caller":"traceutil/trace.go:171","msg":"trace[1603779054] transaction","detail":"{read_only:false; response_revision:2684; number_of_response:1; }","duration":"892.255124ms","start":"2023-11-29T16:31:54.510Z","end":"2023-11-29T16:31:55.402Z","steps":["trace[1603779054] 'process raft request'  (duration: 887.344797ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:31:55.402Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"514.333139ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-11-29T16:31:55.402Z","caller":"traceutil/trace.go:171","msg":"trace[1625078809] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:2684; }","duration":"514.422492ms","start":"2023-11-29T16:31:54.888Z","end":"2023-11-29T16:31:55.402Z","steps":["trace[1625078809] 'agreement among raft nodes before linearized reading'  (duration: 514.224788ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:31:55.402Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-29T16:31:54.510Z","time spent":"892.433517ms","remote":"127.0.0.1:50258","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":4124,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/minions/minikube\" mod_revision:2440 > success:<request_put:<key:\"/registry/minions/minikube\" value_size:4090 >> failure:<request_range:<key:\"/registry/minions/minikube\" > >"}
{"level":"warn","ts":"2023-11-29T16:31:55.402Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-29T16:31:54.888Z","time spent":"514.523418ms","remote":"127.0.0.1:50314","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":28,"request content":"key:\"/registry/health\" "}
{"level":"info","ts":"2023-11-29T16:31:58.431Z","caller":"traceutil/trace.go:171","msg":"trace[1659400630] transaction","detail":"{read_only:false; response_revision:2687; number_of_response:1; }","duration":"479.000417ms","start":"2023-11-29T16:31:57.952Z","end":"2023-11-29T16:31:58.431Z","steps":["trace[1659400630] 'process raft request'  (duration: 478.536342ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-29T16:31:58.432Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-29T16:31:57.952Z","time spent":"479.578672ms","remote":"127.0.0.1:50256","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":585,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:2685 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:512 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >"}
{"level":"info","ts":"2023-11-29T16:31:58.444Z","caller":"traceutil/trace.go:171","msg":"trace[1454785644] linearizableReadLoop","detail":"{readStateIndex:3553; appliedIndex:3551; }","duration":"141.128883ms","start":"2023-11-29T16:31:58.303Z","end":"2023-11-29T16:31:58.444Z","steps":["trace[1454785644] 'read index received'  (duration: 127.879758ms)","trace[1454785644] 'applied index is now lower than readState.Index'  (duration: 13.24692ms)"],"step_count":2}
{"level":"warn","ts":"2023-11-29T16:31:58.445Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"141.697611ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/\" range_end:\"/registry/pods0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2023-11-29T16:31:58.445Z","caller":"traceutil/trace.go:171","msg":"trace[532672108] range","detail":"{range_begin:/registry/pods/; range_end:/registry/pods0; response_count:0; response_revision:2688; }","duration":"141.819691ms","start":"2023-11-29T16:31:58.303Z","end":"2023-11-29T16:31:58.445Z","steps":["trace[532672108] 'agreement among raft nodes before linearized reading'  (duration: 141.36437ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:31:58.445Z","caller":"traceutil/trace.go:171","msg":"trace[1586603323] transaction","detail":"{read_only:false; response_revision:2688; number_of_response:1; }","duration":"199.299703ms","start":"2023-11-29T16:31:58.246Z","end":"2023-11-29T16:31:58.445Z","steps":["trace[1586603323] 'process raft request'  (duration: 198.27152ms)"],"step_count":1}
{"level":"info","ts":"2023-11-29T16:31:59.564Z","caller":"traceutil/trace.go:171","msg":"trace[1533752873] transaction","detail":"{read_only:false; response_revision:2689; number_of_response:1; }","duration":"114.092542ms","start":"2023-11-29T16:31:59.450Z","end":"2023-11-29T16:31:59.564Z","steps":["trace[1533752873] 'process raft request'  (duration: 93.104564ms)","trace[1533752873] 'compare'  (duration: 20.803145ms)"],"step_count":2}

* 
* ==> etcd [fabfae8af6ab] <==
* {"level":"warn","ts":"2023-11-28T17:07:35.856Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.229673275s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-11-28T17:07:35.860Z","caller":"traceutil/trace.go:171","msg":"trace[1916403924] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:805; }","duration":"1.233158238s","start":"2023-11-28T17:07:34.627Z","end":"2023-11-28T17:07:35.860Z","steps":["trace[1916403924] 'agreement among raft nodes before linearized reading'  (duration: 1.228994086s)"],"step_count":1}
{"level":"warn","ts":"2023-11-28T17:07:35.866Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-28T17:07:34.627Z","time spent":"1.239577723s","remote":"127.0.0.1:43400","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":28,"request content":"key:\"/registry/health\" "}
{"level":"info","ts":"2023-11-28T17:07:35.868Z","caller":"traceutil/trace.go:171","msg":"trace[889015313] range","detail":"{range_begin:/registry/resourcequotas/; range_end:/registry/resourcequotas0; response_count:0; response_revision:805; }","duration":"951.513936ms","start":"2023-11-28T17:07:34.905Z","end":"2023-11-28T17:07:35.857Z","steps":["trace[889015313] 'agreement among raft nodes before linearized reading'  (duration: 949.257141ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-28T17:07:35.868Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-28T17:07:34.905Z","time spent":"962.708684ms","remote":"127.0.0.1:43230","response type":"/etcdserverpb.KV/Range","request count":0,"request size":56,"response count":0,"response size":28,"request content":"key:\"/registry/resourcequotas/\" range_end:\"/registry/resourcequotas0\" count_only:true "}
{"level":"warn","ts":"2023-11-28T17:07:37.395Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.460484006s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-11-28T17:07:37.395Z","caller":"traceutil/trace.go:171","msg":"trace[1974127486] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:805; }","duration":"1.460690553s","start":"2023-11-28T17:07:35.934Z","end":"2023-11-28T17:07:37.395Z","steps":["trace[1974127486] 'range keys from in-memory index tree'  (duration: 1.460284046s)"],"step_count":1}
{"level":"warn","ts":"2023-11-28T17:07:37.395Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-28T17:07:35.934Z","time spent":"1.460815843s","remote":"127.0.0.1:43416","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":28,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2023-11-28T17:07:37.396Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"159.728011ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/namespaces/default\" ","response":"range_response_count:1 size:339"}
{"level":"info","ts":"2023-11-28T17:07:37.396Z","caller":"traceutil/trace.go:171","msg":"trace[1448541843] range","detail":"{range_begin:/registry/namespaces/default; range_end:; response_count:1; response_revision:805; }","duration":"159.916553ms","start":"2023-11-28T17:07:37.236Z","end":"2023-11-28T17:07:37.396Z","steps":["trace[1448541843] 'range keys from in-memory index tree'  (duration: 159.566235ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-28T17:07:37.999Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"121.143744ms","expected-duration":"100ms","prefix":"","request":"header:<ID:3238523636612910812 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/masterleases/192.168.58.2\" mod_revision:803 > success:<request_put:<key:\"/registry/masterleases/192.168.58.2\" value_size:66 lease:3238523636612910809 >> failure:<request_range:<key:\"/registry/masterleases/192.168.58.2\" > >>","response":"size:16"}
{"level":"info","ts":"2023-11-28T17:07:37.999Z","caller":"traceutil/trace.go:171","msg":"trace[2020976909] transaction","detail":"{read_only:false; response_revision:806; number_of_response:1; }","duration":"466.146793ms","start":"2023-11-28T17:07:37.533Z","end":"2023-11-28T17:07:37.999Z","steps":["trace[2020976909] 'process raft request'  (duration: 344.674167ms)","trace[2020976909] 'compare'  (duration: 120.930756ms)"],"step_count":2}
{"level":"warn","ts":"2023-11-28T17:07:38.000Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-28T17:07:37.533Z","time spent":"466.291632ms","remote":"127.0.0.1:43188","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":117,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/masterleases/192.168.58.2\" mod_revision:803 > success:<request_put:<key:\"/registry/masterleases/192.168.58.2\" value_size:66 lease:3238523636612910809 >> failure:<request_range:<key:\"/registry/masterleases/192.168.58.2\" > >"}
{"level":"warn","ts":"2023-11-28T17:08:16.916Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"102.612878ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/specs/\" range_end:\"/registry/services/specs0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2023-11-28T17:08:16.916Z","caller":"traceutil/trace.go:171","msg":"trace[537248255] range","detail":"{range_begin:/registry/services/specs/; range_end:/registry/services/specs0; response_count:0; response_revision:817; }","duration":"102.789194ms","start":"2023-11-28T17:08:16.814Z","end":"2023-11-28T17:08:16.916Z","steps":["trace[537248255] 'agreement among raft nodes before linearized reading'  (duration: 102.442194ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:08:16.916Z","caller":"traceutil/trace.go:171","msg":"trace[1228886308] linearizableReadLoop","detail":"{readStateIndex:1152; appliedIndex:1151; }","duration":"102.168183ms","start":"2023-11-28T17:08:16.814Z","end":"2023-11-28T17:08:16.916Z","steps":["trace[1228886308] 'read index received'  (duration: 102.084142ms)","trace[1228886308] 'applied index is now lower than readState.Index'  (duration: 81.749¬µs)"],"step_count":2}
{"level":"info","ts":"2023-11-28T17:08:16.917Z","caller":"traceutil/trace.go:171","msg":"trace[1027619285] transaction","detail":"{read_only:false; response_revision:817; number_of_response:1; }","duration":"168.612614ms","start":"2023-11-28T17:08:16.749Z","end":"2023-11-28T17:08:16.917Z","steps":["trace[1027619285] 'process raft request'  (duration: 167.113172ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:08:22.353Z","caller":"traceutil/trace.go:171","msg":"trace[1169128445] transaction","detail":"{read_only:false; response_revision:819; number_of_response:1; }","duration":"594.868831ms","start":"2023-11-28T17:08:21.758Z","end":"2023-11-28T17:08:22.353Z","steps":["trace[1169128445] 'process raft request'  (duration: 594.48683ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-28T17:08:22.354Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-28T17:08:21.758Z","time spent":"595.304994ms","remote":"127.0.0.1:43270","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":3453,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/minions/minikube\" mod_revision:727 > success:<request_put:<key:\"/registry/minions/minikube\" value_size:3419 >> failure:<request_range:<key:\"/registry/minions/minikube\" > >"}
{"level":"info","ts":"2023-11-28T17:08:22.360Z","caller":"traceutil/trace.go:171","msg":"trace[1316445560] linearizableReadLoop","detail":"{readStateIndex:1156; appliedIndex:1154; }","duration":"349.453708ms","start":"2023-11-28T17:08:22.011Z","end":"2023-11-28T17:08:22.360Z","steps":["trace[1316445560] 'read index received'  (duration: 342.417082ms)","trace[1316445560] 'applied index is now lower than readState.Index'  (duration: 7.034047ms)"],"step_count":2}
{"level":"warn","ts":"2023-11-28T17:08:22.361Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"349.920293ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-11-28T17:08:22.361Z","caller":"traceutil/trace.go:171","msg":"trace[2092486028] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:820; }","duration":"350.061831ms","start":"2023-11-28T17:08:22.011Z","end":"2023-11-28T17:08:22.361Z","steps":["trace[2092486028] 'agreement among raft nodes before linearized reading'  (duration: 349.675964ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-28T17:08:22.361Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-28T17:08:22.011Z","time spent":"350.21861ms","remote":"127.0.0.1:43416","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":28,"request content":"key:\"/registry/health\" "}
{"level":"info","ts":"2023-11-28T17:08:22.361Z","caller":"traceutil/trace.go:171","msg":"trace[471907355] transaction","detail":"{read_only:false; response_revision:820; number_of_response:1; }","duration":"480.472386ms","start":"2023-11-28T17:08:21.881Z","end":"2023-11-28T17:08:22.361Z","steps":["trace[471907355] 'process raft request'  (duration: 478.91075ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-28T17:08:22.362Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-28T17:08:21.881Z","time spent":"480.683761ms","remote":"127.0.0.1:43362","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":673,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" mod_revision:816 > success:<request_put:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" value_size:600 >> failure:<request_range:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" > >"}
{"level":"info","ts":"2023-11-28T17:08:27.456Z","caller":"traceutil/trace.go:171","msg":"trace[1203252323] transaction","detail":"{read_only:false; response_revision:821; number_of_response:1; }","duration":"380.429249ms","start":"2023-11-28T17:08:27.076Z","end":"2023-11-28T17:08:27.456Z","steps":["trace[1203252323] 'process raft request'  (duration: 380.103914ms)"],"step_count":1}
{"level":"warn","ts":"2023-11-28T17:08:27.457Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-11-28T17:08:27.076Z","time spent":"380.666546ms","remote":"127.0.0.1:43362","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":520,"response count":0,"response size":39,"request content":"compare:<target:MOD key:\"/registry/leases/kube-node-lease/minikube\" mod_revision:817 > success:<request_put:<key:\"/registry/leases/kube-node-lease/minikube\" value_size:471 >> failure:<request_range:<key:\"/registry/leases/kube-node-lease/minikube\" > >"}
{"level":"info","ts":"2023-11-28T17:08:27.458Z","caller":"traceutil/trace.go:171","msg":"trace[40091135] linearizableReadLoop","detail":"{readStateIndex:1158; appliedIndex:1158; }","duration":"211.532686ms","start":"2023-11-28T17:08:27.246Z","end":"2023-11-28T17:08:27.458Z","steps":["trace[40091135] 'read index received'  (duration: 211.519644ms)","trace[40091135] 'applied index is now lower than readState.Index'  (duration: 9.687¬µs)"],"step_count":2}
{"level":"warn","ts":"2023-11-28T17:08:27.459Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"211.920053ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/namespaces/default\" ","response":"range_response_count:1 size:339"}
{"level":"info","ts":"2023-11-28T17:08:27.460Z","caller":"traceutil/trace.go:171","msg":"trace[49193022] range","detail":"{range_begin:/registry/namespaces/default; range_end:; response_count:1; response_revision:821; }","duration":"213.656415ms","start":"2023-11-28T17:08:27.246Z","end":"2023-11-28T17:08:27.460Z","steps":["trace[49193022] 'agreement among raft nodes before linearized reading'  (duration: 211.664744ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:09:04.092Z","caller":"traceutil/trace.go:171","msg":"trace[1619514871] transaction","detail":"{read_only:false; response_revision:832; number_of_response:1; }","duration":"163.533383ms","start":"2023-11-28T17:09:03.929Z","end":"2023-11-28T17:09:04.092Z","steps":["trace[1619514871] 'process raft request'  (duration: 163.257099ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:09:14.525Z","caller":"traceutil/trace.go:171","msg":"trace[104401748] transaction","detail":"{read_only:false; response_revision:835; number_of_response:1; }","duration":"195.149016ms","start":"2023-11-28T17:09:14.330Z","end":"2023-11-28T17:09:14.525Z","steps":["trace[104401748] 'process raft request'  (duration: 194.879246ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:10:47.625Z","caller":"traceutil/trace.go:171","msg":"trace[498198059] transaction","detail":"{read_only:false; response_revision:863; number_of_response:1; }","duration":"119.605566ms","start":"2023-11-28T17:10:47.505Z","end":"2023-11-28T17:10:47.625Z","steps":["trace[498198059] 'process raft request'  (duration: 119.329749ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:11:08.365Z","caller":"traceutil/trace.go:171","msg":"trace[1428520706] compact","detail":"{revision:780; response_revision:870; }","duration":"104.687977ms","start":"2023-11-28T17:11:08.260Z","end":"2023-11-28T17:11:08.365Z","steps":["trace[1428520706] 'check and update compact revision'  (duration: 99.338679ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:11:08.365Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":780}
{"level":"info","ts":"2023-11-28T17:11:08.368Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":780,"took":"609.098¬µs","hash":4080050666}
{"level":"info","ts":"2023-11-28T17:11:08.368Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":4080050666,"revision":780,"compact-revision":689}
{"level":"info","ts":"2023-11-28T17:11:59.124Z","caller":"traceutil/trace.go:171","msg":"trace[1227628962] transaction","detail":"{read_only:false; response_revision:886; number_of_response:1; }","duration":"100.731299ms","start":"2023-11-28T17:11:59.024Z","end":"2023-11-28T17:11:59.124Z","steps":["trace[1227628962] 'process raft request'  (duration: 100.473329ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:12:19.839Z","caller":"traceutil/trace.go:171","msg":"trace[1020637659] transaction","detail":"{read_only:false; response_revision:892; number_of_response:1; }","duration":"101.756581ms","start":"2023-11-28T17:12:19.738Z","end":"2023-11-28T17:12:19.839Z","steps":["trace[1020637659] 'process raft request'  (duration: 101.391748ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:12:27.431Z","caller":"traceutil/trace.go:171","msg":"trace[168973879] transaction","detail":"{read_only:false; response_revision:894; number_of_response:1; }","duration":"114.781534ms","start":"2023-11-28T17:12:27.316Z","end":"2023-11-28T17:12:27.431Z","steps":["trace[168973879] 'process raft request'  (duration: 104.856671ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:13:30.938Z","caller":"traceutil/trace.go:171","msg":"trace[1074195846] transaction","detail":"{read_only:false; response_revision:913; number_of_response:1; }","duration":"121.183171ms","start":"2023-11-28T17:13:30.817Z","end":"2023-11-28T17:13:30.938Z","steps":["trace[1074195846] 'process raft request'  (duration: 120.892649ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:13:35.230Z","caller":"traceutil/trace.go:171","msg":"trace[248733718] transaction","detail":"{read_only:false; response_revision:915; number_of_response:1; }","duration":"121.643116ms","start":"2023-11-28T17:13:35.108Z","end":"2023-11-28T17:13:35.230Z","steps":["trace[248733718] 'process raft request'  (duration: 121.400288ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:13:56.169Z","caller":"traceutil/trace.go:171","msg":"trace[1505607984] transaction","detail":"{read_only:false; response_revision:921; number_of_response:1; }","duration":"113.809835ms","start":"2023-11-28T17:13:56.055Z","end":"2023-11-28T17:13:56.169Z","steps":["trace[1505607984] 'process raft request'  (duration: 113.541436ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:14:17.556Z","caller":"traceutil/trace.go:171","msg":"trace[1733265722] transaction","detail":"{read_only:false; response_revision:928; number_of_response:1; }","duration":"135.170565ms","start":"2023-11-28T17:14:17.421Z","end":"2023-11-28T17:14:17.556Z","steps":["trace[1733265722] 'process raft request'  (duration: 117.521804ms)","trace[1733265722] 'compare'  (duration: 17.36271ms)"],"step_count":2}
{"level":"info","ts":"2023-11-28T17:14:52.871Z","caller":"traceutil/trace.go:171","msg":"trace[1977354158] transaction","detail":"{read_only:false; response_revision:938; number_of_response:1; }","duration":"106.39214ms","start":"2023-11-28T17:14:52.764Z","end":"2023-11-28T17:14:52.871Z","steps":["trace[1977354158] 'process raft request'  (duration: 106.11732ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:15:33.826Z","caller":"traceutil/trace.go:171","msg":"trace[1763205543] transaction","detail":"{read_only:false; response_revision:950; number_of_response:1; }","duration":"129.948333ms","start":"2023-11-28T17:15:33.696Z","end":"2023-11-28T17:15:33.826Z","steps":["trace[1763205543] 'process raft request'  (duration: 129.46196ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:15:38.866Z","caller":"traceutil/trace.go:171","msg":"trace[258125434] transaction","detail":"{read_only:false; response_revision:952; number_of_response:1; }","duration":"145.527928ms","start":"2023-11-28T17:15:38.721Z","end":"2023-11-28T17:15:38.866Z","steps":["trace[258125434] 'process raft request'  (duration: 145.204598ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:15:44.036Z","caller":"traceutil/trace.go:171","msg":"trace[1991281473] transaction","detail":"{read_only:false; response_revision:953; number_of_response:1; }","duration":"114.445521ms","start":"2023-11-28T17:15:43.922Z","end":"2023-11-28T17:15:44.036Z","steps":["trace[1991281473] 'process raft request'  (duration: 113.974264ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:16:04.670Z","caller":"traceutil/trace.go:171","msg":"trace[2007069507] transaction","detail":"{read_only:false; response_revision:959; number_of_response:1; }","duration":"117.718772ms","start":"2023-11-28T17:16:04.553Z","end":"2023-11-28T17:16:04.670Z","steps":["trace[2007069507] 'process raft request'  (duration: 117.287166ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:16:08.415Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":870}
{"level":"info","ts":"2023-11-28T17:16:08.425Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":870,"took":"4.641644ms","hash":1580248045}
{"level":"info","ts":"2023-11-28T17:16:08.425Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1580248045,"revision":870,"compact-revision":780}
{"level":"warn","ts":"2023-11-28T17:16:09.656Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"106.660141ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/ingress/\" range_end:\"/registry/ingress0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-11-28T17:16:09.657Z","caller":"traceutil/trace.go:171","msg":"trace[1072112604] range","detail":"{range_begin:/registry/ingress/; range_end:/registry/ingress0; response_count:0; response_revision:962; }","duration":"106.848895ms","start":"2023-11-28T17:16:09.550Z","end":"2023-11-28T17:16:09.657Z","steps":["trace[1072112604] 'count revisions from in-memory index tree'  (duration: 106.421335ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:17:00.875Z","caller":"traceutil/trace.go:171","msg":"trace[1828681786] transaction","detail":"{read_only:false; response_revision:977; number_of_response:1; }","duration":"100.934622ms","start":"2023-11-28T17:17:00.774Z","end":"2023-11-28T17:17:00.875Z","steps":["trace[1828681786] 'process raft request'  (duration: 100.645929ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:17:31.597Z","caller":"traceutil/trace.go:171","msg":"trace[66648097] transaction","detail":"{read_only:false; response_revision:986; number_of_response:1; }","duration":"126.272946ms","start":"2023-11-28T17:17:31.471Z","end":"2023-11-28T17:17:31.597Z","steps":["trace[66648097] 'process raft request'  (duration: 126.089987ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:17:37.475Z","caller":"traceutil/trace.go:171","msg":"trace[547695850] transaction","detail":"{read_only:false; response_revision:988; number_of_response:1; }","duration":"121.52338ms","start":"2023-11-28T17:17:37.354Z","end":"2023-11-28T17:17:37.475Z","steps":["trace[547695850] 'process raft request'  (duration: 116.467432ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:18:18.565Z","caller":"traceutil/trace.go:171","msg":"trace[1336562244] transaction","detail":"{read_only:false; response_revision:1000; number_of_response:1; }","duration":"110.571573ms","start":"2023-11-28T17:18:18.455Z","end":"2023-11-28T17:18:18.565Z","steps":["trace[1336562244] 'process raft request'  (duration: 110.397878ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:18:27.477Z","caller":"traceutil/trace.go:171","msg":"trace[576857446] transaction","detail":"{read_only:false; response_revision:1002; number_of_response:1; }","duration":"113.821012ms","start":"2023-11-28T17:18:27.363Z","end":"2023-11-28T17:18:27.477Z","steps":["trace[576857446] 'process raft request'  (duration: 103.894792ms)"],"step_count":1}
{"level":"info","ts":"2023-11-28T17:18:57.503Z","caller":"traceutil/trace.go:171","msg":"trace[1789573099] transaction","detail":"{read_only:false; response_revision:1012; number_of_response:1; }","duration":"139.550337ms","start":"2023-11-28T17:18:57.363Z","end":"2023-11-28T17:18:57.503Z","steps":["trace[1789573099] 'process raft request'  (duration: 134.619151ms)"],"step_count":1}

* 
* ==> kernel <==
*  16:32:03 up 31 min,  0 users,  load average: 1.67, 1.56, 1.64
Linux minikube 6.4.16-linuxkit #1 SMP PREEMPT_DYNAMIC Thu Nov 16 10:55:59 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.2 LTS"

* 
* ==> kube-apiserver [9372752612d5] <==
* Trace[2121737643]: [12.166258032s] [12.166258032s] END
I1129 16:11:18.950379       1 trace.go:219] Trace[398424443]: "GuaranteedUpdate etcd3" audit-id:,key:/masterleases/192.168.58.2,type:*v1.Endpoints,resource:apiServerIPInfo (29-Nov-2023 16:11:18.428) (total time: 516ms):
Trace[398424443]: ---"initial value restored" 137ms (16:11:18.565)
Trace[398424443]: ---"Transaction prepared" 256ms (16:11:18.821)
Trace[398424443]: ---"Txn call completed" 123ms (16:11:18.950)
Trace[398424443]: [516.788182ms] [516.788182ms] END
I1129 16:11:19.004966       1 trace.go:219] Trace[256962549]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:e9422f62-b6d3-4997-8b5a-8934db8cce4b,client:192.168.58.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/kube-system/pods/kube-apiserver-minikube/status,user-agent:kubelet/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PATCH (29-Nov-2023 16:11:18.474) (total time: 525ms):
Trace[256962549]: ["GuaranteedUpdate etcd3" audit-id:e9422f62-b6d3-4997-8b5a-8934db8cce4b,key:/pods/kube-system/kube-apiserver-minikube,type:*core.Pod,resource:pods 513ms (16:11:18.486)
Trace[256962549]:  ---"About to Encode" 389ms (16:11:18.899)
Trace[256962549]:  ---"Txn call completed" 87ms (16:11:18.993)]
Trace[256962549]: ---"About to check admission control" 380ms (16:11:18.891)
Trace[256962549]: ---"Object stored in database" 103ms (16:11:18.999)
Trace[256962549]: [525.250844ms] [525.250844ms] END
I1129 16:11:45.861389       1 trace.go:219] Trace[682620981]: "Get" accept:application/json, */*,audit-id:d3fe0854-eaf7-4e7b-8490-ba9c8e909780,client:192.168.58.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:GET (29-Nov-2023 16:11:45.009) (total time: 851ms):
Trace[682620981]: ---"About to write a response" 850ms (16:11:45.860)
Trace[682620981]: [851.523491ms] [851.523491ms] END
I1129 16:12:06.237384       1 trace.go:219] Trace[536560956]: "Update" accept:application/json, */*,audit-id:79b357d1-eac2-4b69-86f4-c5ba86677aa9,client:192.168.58.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (29-Nov-2023 16:12:05.663) (total time: 572ms):
Trace[536560956]: ["GuaranteedUpdate etcd3" audit-id:79b357d1-eac2-4b69-86f4-c5ba86677aa9,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 571ms (16:12:05.664)
Trace[536560956]:  ---"Txn call completed" 538ms (16:12:06.235)]
Trace[536560956]: [572.361762ms] [572.361762ms] END
I1129 16:13:31.552337       1 trace.go:219] Trace[1815614570]: "Update" accept:application/json, */*,audit-id:4a88e1c3-5f72-4ba6-8f1b-f03c2a77a3e0,client:192.168.58.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (29-Nov-2023 16:13:30.924) (total time: 627ms):
Trace[1815614570]: ["GuaranteedUpdate etcd3" audit-id:4a88e1c3-5f72-4ba6-8f1b-f03c2a77a3e0,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 627ms (16:13:30.924)
Trace[1815614570]:  ---"Txn call completed" 625ms (16:13:31.551)]
Trace[1815614570]: [627.861483ms] [627.861483ms] END
I1129 16:23:52.046930       1 trace.go:219] Trace[1685938584]: "List" accept:application/json, */*,audit-id:a67f4f45-56d3-4fde-b76a-35bd947db1fe,client:192.168.58.1,protocol:HTTP/2.0,resource:pods,scope:namespace,url:/api/v1/namespaces/ingress-nginx/pods,user-agent:minikube/v0.0.0 (linux/amd64) kubernetes/$Format,verb:LIST (29-Nov-2023 16:23:51.459) (total time: 578ms):
Trace[1685938584]: ["List(recursive=true) etcd3" audit-id:a67f4f45-56d3-4fde-b76a-35bd947db1fe,key:/pods/ingress-nginx,resourceVersion:,resourceVersionMatch:,limit:0,continue: 577ms (16:23:51.460)]
Trace[1685938584]: [578.041161ms] [578.041161ms] END
I1129 16:23:52.048768       1 trace.go:219] Trace[1578687236]: "Update" accept:application/json, */*,audit-id:774cf7d2-0110-45ce-81d3-10ece0b7d00f,client:192.168.58.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (29-Nov-2023 16:23:51.051) (total time: 982ms):
Trace[1578687236]: ["GuaranteedUpdate etcd3" audit-id:774cf7d2-0110-45ce-81d3-10ece0b7d00f,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 981ms (16:23:51.052)
Trace[1578687236]:  ---"Txn call completed" 971ms (16:23:52.033)]
Trace[1578687236]: [982.46322ms] [982.46322ms] END
I1129 16:23:54.029839       1 trace.go:219] Trace[2097516130]: "Patch" accept:application/vnd.kubernetes.protobuf, */*,audit-id:b6d51472-8e7d-4339-97bb-5f5ce52347ab,client:192.168.58.2,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/ingress-nginx/events/ingress-nginx-admission-patch-b965k.179c2375cbf868bb,user-agent:kube-scheduler/v1.27.3 (linux/amd64) kubernetes/25b4e43/scheduler,verb:PATCH (29-Nov-2023 16:23:53.182) (total time: 845ms):
Trace[2097516130]: ["GuaranteedUpdate etcd3" audit-id:b6d51472-8e7d-4339-97bb-5f5ce52347ab,key:/events/ingress-nginx/ingress-nginx-admission-patch-b965k.179c2375cbf868bb,type:*core.Event,resource:events 846ms (16:23:53.183)
Trace[2097516130]:  ---"Transaction prepared" 447ms (16:23:53.643)
Trace[2097516130]:  ---"Txn call completed" 384ms (16:23:54.027)]
Trace[2097516130]: ---"Object stored in database" 832ms (16:23:54.027)
Trace[2097516130]: [845.89479ms] [845.89479ms] END
I1129 16:23:54.977449       1 trace.go:219] Trace[2049326162]: "List" accept:application/json, */*,audit-id:80b24548-67bd-4396-9899-c0b3b5215ef9,client:192.168.58.1,protocol:HTTP/2.0,resource:pods,scope:namespace,url:/api/v1/namespaces/ingress-nginx/pods,user-agent:minikube/v0.0.0 (linux/amd64) kubernetes/$Format,verb:LIST (29-Nov-2023 16:23:54.462) (total time: 514ms):
Trace[2049326162]: ["List(recursive=true) etcd3" audit-id:80b24548-67bd-4396-9899-c0b3b5215ef9,key:/pods/ingress-nginx,resourceVersion:,resourceVersionMatch:,limit:0,continue: 514ms (16:23:54.462)]
Trace[2049326162]: [514.842528ms] [514.842528ms] END
I1129 16:23:54.997271       1 trace.go:219] Trace[152481912]: "Get" accept:application/json, */*,audit-id:63e98c52-5d3d-4b82-8e2a-e7c06ccd2fcf,client:192.168.58.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:GET (29-Nov-2023 16:23:54.054) (total time: 942ms):
Trace[152481912]: ---"About to write a response" 942ms (16:23:54.996)
Trace[152481912]: [942.514564ms] [942.514564ms] END
I1129 16:23:55.008519       1 trace.go:219] Trace[547084705]: "Patch" accept:application/vnd.kubernetes.protobuf, */*,audit-id:ecdd8be8-4150-4396-bcb8-02a10c0f476a,client:192.168.58.2,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/ingress-nginx/events/ingress-nginx-admission-create-56md6.179c2375f937dda6,user-agent:kube-scheduler/v1.27.3 (linux/amd64) kubernetes/25b4e43/scheduler,verb:PATCH (29-Nov-2023 16:23:54.041) (total time: 967ms):
Trace[547084705]: ["GuaranteedUpdate etcd3" audit-id:ecdd8be8-4150-4396-bcb8-02a10c0f476a,key:/events/ingress-nginx/ingress-nginx-admission-create-56md6.179c2375f937dda6,type:*core.Event,resource:events 967ms (16:23:54.041)
Trace[547084705]:  ---"Txn call completed" 952ms (16:23:54.999)]
Trace[547084705]: ---"Object stored in database" 961ms (16:23:55.008)
Trace[547084705]: [967.233955ms] [967.233955ms] END
I1129 16:23:56.503491       1 trace.go:219] Trace[1309474448]: "List" accept:application/json, */*,audit-id:3b6f449c-74a6-4770-8c2f-419133ae5571,client:192.168.58.1,protocol:HTTP/2.0,resource:pods,scope:namespace,url:/api/v1/namespaces/ingress-nginx/pods,user-agent:minikube/v0.0.0 (linux/amd64) kubernetes/$Format,verb:LIST (29-Nov-2023 16:23:55.979) (total time: 524ms):
Trace[1309474448]: ["List(recursive=true) etcd3" audit-id:3b6f449c-74a6-4770-8c2f-419133ae5571,key:/pods/ingress-nginx,resourceVersion:,resourceVersionMatch:,limit:0,continue: 523ms (16:23:55.979)]
Trace[1309474448]: [524.040109ms] [524.040109ms] END
I1129 16:29:04.071562       1 trace.go:219] Trace[1918346472]: "Update" accept:application/json, */*,audit-id:4f017dbf-e071-4d1a-84c5-c092097e7008,client:192.168.58.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (29-Nov-2023 16:29:03.472) (total time: 598ms):
Trace[1918346472]: ["GuaranteedUpdate etcd3" audit-id:4f017dbf-e071-4d1a-84c5-c092097e7008,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 598ms (16:29:03.473)
Trace[1918346472]:  ---"Txn call completed" 596ms (16:29:04.071)]
Trace[1918346472]: [598.9602ms] [598.9602ms] END
I1129 16:31:55.404877       1 trace.go:219] Trace[2119503534]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:11afeb48-01ec-4c79-8474-3ca50ce86a2a,client:192.168.58.2,protocol:HTTP/2.0,resource:nodes,scope:resource,url:/api/v1/nodes/minikube/status,user-agent:kubelet/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PATCH (29-Nov-2023 16:31:54.495) (total time: 909ms):
Trace[2119503534]: ["GuaranteedUpdate etcd3" audit-id:11afeb48-01ec-4c79-8474-3ca50ce86a2a,key:/minions/minikube,type:*core.Node,resource:nodes 908ms (16:31:54.495)
Trace[2119503534]:  ---"Txn call completed" 895ms (16:31:55.404)]
Trace[2119503534]: ---"Object stored in database" 896ms (16:31:55.404)
Trace[2119503534]: [909.336286ms] [909.336286ms] END

* 
* ==> kube-apiserver [f5d3dac36390] <==
* Trace[2128491427]:  ---"Txn call completed" 6492ms (16:42:58.580)]
Trace[2128491427]: [6.495498318s] [6.495498318s] END
I1128 16:42:58.634046       1 trace.go:219] Trace[442329559]: "Get" accept:application/vnd.kubernetes.protobuf, */*,audit-id:a9db876a-2d79-4ff3-a2e7-18715aa3d7f7,client:127.0.0.1,protocol:HTTP/2.0,resource:namespaces,scope:resource,url:/api/v1/namespaces/default,user-agent:kube-apiserver/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:GET (28-Nov-2023 16:42:57.065) (total time: 1568ms):
Trace[442329559]: ---"About to write a response" 1568ms (16:42:58.633)
Trace[442329559]: [1.568610228s] [1.568610228s] END
I1128 16:42:58.634069       1 trace.go:219] Trace[344576482]: "Create" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:03bc2b22-9f70-47e1-8bcc-e854dcaa5446,client:192.168.58.2,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events,user-agent:kubelet/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:POST (28-Nov-2023 16:42:56.414) (total time: 2216ms):
Trace[344576482]: ["Create etcd3" audit-id:03bc2b22-9f70-47e1-8bcc-e854dcaa5446,key:/events/kube-system/kube-apiserver-minikube.179bd7169e94c42f,type:*core.Event,resource:events 2218ms (16:42:56.415)
Trace[344576482]:  ---"Txn call succeeded" 2214ms (16:42:58.630)]
Trace[344576482]: [2.216129289s] [2.216129289s] END
I1128 16:42:58.653178       1 trace.go:219] Trace[219632898]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:bfe7abc5-bc17-4c0a-800f-ddeb540576b4,client:127.0.0.1,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,user-agent:kube-apiserver/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PUT (28-Nov-2023 16:42:56.298) (total time: 2353ms):
Trace[219632898]: ---"limitedReadBody succeeded" len:603 310ms (16:42:56.609)
Trace[219632898]: ["GuaranteedUpdate etcd3" audit-id:bfe7abc5-bc17-4c0a-800f-ddeb540576b4,key:/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,type:*coordination.Lease,resource:leases.coordination.k8s.io 2043ms (16:42:56.609)
Trace[219632898]:  ---"Txn call completed" 2040ms (16:42:58.651)]
Trace[219632898]: [2.353870429s] [2.353870429s] END
I1128 16:48:49.676714       1 trace.go:219] Trace[1053358758]: "GuaranteedUpdate etcd3" audit-id:,key:/masterleases/192.168.58.2,type:*v1.Endpoints,resource:apiServerIPInfo (28-Nov-2023 16:48:47.070) (total time: 2605ms):
Trace[1053358758]: ---"Transaction prepared" 1152ms (16:48:48.225)
Trace[1053358758]: ---"Txn call completed" 1450ms (16:48:49.676)
Trace[1053358758]: [2.605108336s] [2.605108336s] END
I1128 16:49:00.251945       1 trace.go:219] Trace[438493985]: "Update" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:d1853bdc-093e-48bf-8184-62862f21c563,client:192.168.58.2,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube,user-agent:kubelet/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PUT (28-Nov-2023 16:48:56.638) (total time: 3612ms):
Trace[438493985]: ["GuaranteedUpdate etcd3" audit-id:d1853bdc-093e-48bf-8184-62862f21c563,key:/leases/kube-node-lease/minikube,type:*coordination.Lease,resource:leases.coordination.k8s.io 3612ms (16:48:56.639)
Trace[438493985]:  ---"Txn call completed" 3610ms (16:49:00.251)]
Trace[438493985]: [3.612820493s] [3.612820493s] END
I1128 16:49:00.254446       1 trace.go:219] Trace[167128596]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:67e71388-be9a-4ff1-b656-6b9d9da926a4,client:127.0.0.1,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,user-agent:kube-apiserver/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PUT (28-Nov-2023 16:48:56.650) (total time: 3604ms):
Trace[167128596]: ["GuaranteedUpdate etcd3" audit-id:67e71388-be9a-4ff1-b656-6b9d9da926a4,key:/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,type:*coordination.Lease,resource:leases.coordination.k8s.io 3604ms (16:48:56.650)
Trace[167128596]:  ---"Txn call completed" 3602ms (16:49:00.253)]
Trace[167128596]: [3.604143053s] [3.604143053s] END
I1128 16:49:00.267709       1 trace.go:219] Trace[1863561863]: "Get" accept:application/vnd.kubernetes.protobuf, */*,audit-id:1e991239-0c06-40eb-ae19-37881bc774ba,client:127.0.0.1,protocol:HTTP/2.0,resource:namespaces,scope:resource,url:/api/v1/namespaces/default,user-agent:kube-apiserver/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:GET (28-Nov-2023 16:48:57.066) (total time: 3201ms):
Trace[1863561863]: ---"About to write a response" 3201ms (16:49:00.267)
Trace[1863561863]: [3.20156498s] [3.20156498s] END
I1128 16:49:00.429946       1 trace.go:219] Trace[211592805]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:1ac50097-c179-497c-91c1-c74849d82aa8,client:192.168.58.2,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events/kube-apiserver-minikube.179bd7169e94c42f,user-agent:kubelet/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PATCH (28-Nov-2023 16:48:56.359) (total time: 4070ms):
Trace[211592805]: ["GuaranteedUpdate etcd3" audit-id:1ac50097-c179-497c-91c1-c74849d82aa8,key:/events/kube-system/kube-apiserver-minikube.179bd7169e94c42f,type:*core.Event,resource:events 4069ms (16:48:56.359)
Trace[211592805]:  ---"initial value restored" 3894ms (16:49:00.254)
Trace[211592805]:  ---"Transaction prepared" 151ms (16:49:00.410)]
Trace[211592805]: ---"Object stored in database" 171ms (16:49:00.429)
Trace[211592805]: [4.070123542s] [4.070123542s] END
I1128 16:57:33.484887       1 trace.go:219] Trace[1780765304]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:1d74f180-4c13-4efa-8a15-5483bcd23042,client:127.0.0.1,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,user-agent:kube-apiserver/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PUT (28-Nov-2023 16:57:31.760) (total time: 1724ms):
Trace[1780765304]: ["GuaranteedUpdate etcd3" audit-id:1d74f180-4c13-4efa-8a15-5483bcd23042,key:/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,type:*coordination.Lease,resource:leases.coordination.k8s.io 1724ms (16:57:31.760)
Trace[1780765304]:  ---"Txn call completed" 1722ms (16:57:33.484)]
Trace[1780765304]: [1.724633776s] [1.724633776s] END
I1128 16:57:58.138317       1 trace.go:219] Trace[1767602417]: "GuaranteedUpdate etcd3" audit-id:,key:/masterleases/192.168.58.2,type:*v1.Endpoints,resource:apiServerIPInfo (28-Nov-2023 16:57:57.152) (total time: 986ms):
Trace[1767602417]: ---"Transaction prepared" 911ms (16:57:58.066)
Trace[1767602417]: ---"Txn call completed" 72ms (16:57:58.138)
Trace[1767602417]: [986.038209ms] [986.038209ms] END
I1128 16:58:05.891426       1 trace.go:219] Trace[117521444]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:93ad3c7e-1aa4-4569-b6b7-e301909a8db1,client:127.0.0.1,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,user-agent:kube-apiserver/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PUT (28-Nov-2023 16:58:04.505) (total time: 1385ms):
Trace[117521444]: ["GuaranteedUpdate etcd3" audit-id:93ad3c7e-1aa4-4569-b6b7-e301909a8db1,key:/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,type:*coordination.Lease,resource:leases.coordination.k8s.io 1385ms (16:58:04.506)
Trace[117521444]:  ---"Txn call completed" 1383ms (16:58:05.890)]
Trace[117521444]: [1.385360651s] [1.385360651s] END
I1128 17:07:35.889012       1 trace.go:219] Trace[68391758]: "Update" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:790edaa7-7243-42dd-b77e-21167a39c8fd,client:192.168.58.2,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube,user-agent:kubelet/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PUT (28-Nov-2023 17:07:34.165) (total time: 1723ms):
Trace[68391758]: ["GuaranteedUpdate etcd3" audit-id:790edaa7-7243-42dd-b77e-21167a39c8fd,key:/leases/kube-node-lease/minikube,type:*coordination.Lease,resource:leases.coordination.k8s.io 1723ms (17:07:34.165)
Trace[68391758]:  ---"Txn call completed" 1716ms (17:07:35.882)]
Trace[68391758]: [1.72361923s] [1.72361923s] END
I1128 17:07:38.001564       1 trace.go:219] Trace[1420616618]: "GuaranteedUpdate etcd3" audit-id:,key:/masterleases/192.168.58.2,type:*v1.Endpoints,resource:apiServerIPInfo (28-Nov-2023 17:07:37.407) (total time: 593ms):
Trace[1420616618]: ---"Transaction prepared" 110ms (17:07:37.532)
Trace[1420616618]: ---"Txn call completed" 468ms (17:07:38.001)
Trace[1420616618]: [593.757855ms] [593.757855ms] END
I1128 17:08:22.364720       1 trace.go:219] Trace[391197586]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:22e8216d-659a-44b7-93a3-a015e197f245,client:192.168.58.2,protocol:HTTP/2.0,resource:nodes,scope:resource,url:/api/v1/nodes/minikube/status,user-agent:kubelet/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PATCH (28-Nov-2023 17:08:21.752) (total time: 611ms):
Trace[391197586]: ["GuaranteedUpdate etcd3" audit-id:22e8216d-659a-44b7-93a3-a015e197f245,key:/minions/minikube,type:*core.Node,resource:nodes 611ms (17:08:21.753)
Trace[391197586]:  ---"Txn call completed" 606ms (17:08:22.363)]
Trace[391197586]: ---"Object stored in database" 607ms (17:08:22.364)
Trace[391197586]: [611.83527ms] [611.83527ms] END

* 
* ==> kube-controller-manager [5d494ce9fe5d] <==
* I1128 16:42:35.845862       1 controllermanager.go:616] "Warning: skipping controller" controller="route"
I1128 16:42:35.994215       1 controllermanager.go:638] "Started controller" controller="persistentvolume-expander"
I1128 16:42:35.994334       1 expand_controller.go:339] "Starting expand controller"
I1128 16:42:35.994413       1 shared_informer.go:311] Waiting for caches to sync for expand
I1128 16:42:36.409319       1 controllermanager.go:638] "Started controller" controller="clusterrole-aggregation"
I1128 16:42:36.409774       1 clusterroleaggregation_controller.go:189] "Starting ClusterRoleAggregator controller"
I1128 16:42:36.409808       1 shared_informer.go:311] Waiting for caches to sync for ClusterRoleAggregator
I1128 16:42:36.427780       1 shared_informer.go:311] Waiting for caches to sync for resource quota
I1128 16:42:36.466992       1 actual_state_of_world.go:547] "Failed to update statusUpdateNeeded field in actual state of world" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"minikube\" does not exist"
W1128 16:42:36.467279       1 topologycache.go:232] Can't get CPU or zone information for minikube node
I1128 16:42:36.487473       1 shared_informer.go:318] Caches are synced for service account
I1128 16:42:36.495362       1 shared_informer.go:318] Caches are synced for expand
I1128 16:42:36.502001       1 shared_informer.go:318] Caches are synced for bootstrap_signer
I1128 16:42:36.506728       1 shared_informer.go:318] Caches are synced for endpoint_slice_mirroring
I1128 16:42:36.526903       1 shared_informer.go:318] Caches are synced for node
I1128 16:42:36.530608       1 range_allocator.go:174] "Sending events to api server"
I1128 16:42:36.529040       1 shared_informer.go:318] Caches are synced for TTL
I1128 16:42:36.530228       1 shared_informer.go:318] Caches are synced for namespace
I1128 16:42:36.531489       1 range_allocator.go:178] "Starting range CIDR allocator"
I1128 16:42:36.530312       1 shared_informer.go:318] Caches are synced for crt configmap
I1128 16:42:36.533150       1 shared_informer.go:311] Waiting for caches to sync for cidrallocator
I1128 16:42:36.533375       1 shared_informer.go:318] Caches are synced for cidrallocator
I1128 16:42:36.538315       1 shared_informer.go:318] Caches are synced for certificate-csrapproving
I1128 16:42:36.559464       1 shared_informer.go:318] Caches are synced for PV protection
I1128 16:42:36.601247       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-serving
I1128 16:42:36.609755       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kube-apiserver-client
I1128 16:42:36.613880       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-legacy-unknown
I1128 16:42:36.611766       1 shared_informer.go:311] Waiting for caches to sync for garbage collector
I1128 16:42:36.614797       1 shared_informer.go:318] Caches are synced for ClusterRoleAggregator
I1128 16:42:36.615347       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-client
I1128 16:42:36.646882       1 shared_informer.go:318] Caches are synced for stateful set
I1128 16:42:36.652636       1 shared_informer.go:318] Caches are synced for attach detach
I1128 16:42:36.652764       1 shared_informer.go:318] Caches are synced for resource quota
I1128 16:42:36.657861       1 shared_informer.go:318] Caches are synced for HPA
I1128 16:42:36.669415       1 shared_informer.go:318] Caches are synced for deployment
I1128 16:42:36.682231       1 shared_informer.go:318] Caches are synced for TTL after finished
I1128 16:42:36.683326       1 shared_informer.go:318] Caches are synced for endpoint_slice
I1128 16:42:36.684712       1 shared_informer.go:318] Caches are synced for ephemeral
I1128 16:42:36.698102       1 shared_informer.go:318] Caches are synced for GC
I1128 16:42:36.700133       1 shared_informer.go:318] Caches are synced for ReplicationController
I1128 16:42:36.702206       1 shared_informer.go:318] Caches are synced for PVC protection
I1128 16:42:36.703453       1 shared_informer.go:318] Caches are synced for ReplicaSet
I1128 16:42:36.707132       1 shared_informer.go:318] Caches are synced for cronjob
I1128 16:42:36.708387       1 shared_informer.go:318] Caches are synced for persistent volume
I1128 16:42:36.715470       1 shared_informer.go:318] Caches are synced for job
I1128 16:42:36.723620       1 range_allocator.go:380] "Set node PodCIDR" node="minikube" podCIDRs=[10.244.0.0/24]
I1128 16:42:36.725395       1 shared_informer.go:318] Caches are synced for endpoint
I1128 16:42:36.726880       1 shared_informer.go:318] Caches are synced for disruption
I1128 16:42:36.729389       1 shared_informer.go:318] Caches are synced for resource quota
I1128 16:42:36.729966       1 shared_informer.go:318] Caches are synced for taint
I1128 16:42:36.730571       1 node_lifecycle_controller.go:1223] "Initializing eviction metric for zone" zone=""
I1128 16:42:36.731222       1 node_lifecycle_controller.go:875] "Missing timestamp for Node. Assuming now as a timestamp" node="minikube"
I1128 16:42:36.731600       1 node_lifecycle_controller.go:1069] "Controller detected that zone is now in new state" zone="" newState=Normal
I1128 16:42:36.732668       1 event.go:307] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I1128 16:42:36.732837       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I1128 16:42:36.732944       1 taint_manager.go:211] "Sending events to api server"
I1128 16:42:36.739228       1 shared_informer.go:318] Caches are synced for daemon sets
I1128 16:42:37.050446       1 shared_informer.go:318] Caches are synced for garbage collector
I1128 16:42:37.050510       1 garbagecollector.go:166] "All resource monitors have synced. Proceeding to collect garbage"
I1128 16:42:37.114594       1 shared_informer.go:318] Caches are synced for garbage collector

* 
* ==> kube-controller-manager [feff91b77d87] <==
* I1129 16:02:27.150514       1 shared_informer.go:318] Caches are synced for taint
I1129 16:02:27.168262       1 shared_informer.go:318] Caches are synced for expand
I1129 16:02:27.144264       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kube-apiserver-client
I1129 16:02:27.178499       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I1129 16:02:27.178545       1 taint_manager.go:211] "Sending events to api server"
I1129 16:02:27.178931       1 node_lifecycle_controller.go:1223] "Initializing eviction metric for zone" zone=""
I1129 16:02:27.179252       1 node_lifecycle_controller.go:875] "Missing timestamp for Node. Assuming now as a timestamp" node="minikube"
I1129 16:02:27.179334       1 node_lifecycle_controller.go:1069] "Controller detected that zone is now in new state" zone="" newState=Normal
I1129 16:02:27.144483       1 shared_informer.go:318] Caches are synced for deployment
I1129 16:02:27.188841       1 shared_informer.go:318] Caches are synced for ReplicaSet
I1129 16:02:27.204410       1 shared_informer.go:318] Caches are synced for resource quota
I1129 16:02:27.227689       1 event.go:307] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I1129 16:02:27.246351       1 shared_informer.go:318] Caches are synced for resource quota
I1129 16:02:27.265773       1 shared_informer.go:311] Waiting for caches to sync for garbage collector
I1129 16:02:27.278202       1 shared_informer.go:318] Caches are synced for HPA
I1129 16:02:27.531846       1 shared_informer.go:318] Caches are synced for garbage collector
I1129 16:02:27.534257       1 garbagecollector.go:166] "All resource monitors have synced. Proceeding to collect garbage"
I1129 16:02:27.581848       1 shared_informer.go:318] Caches are synced for garbage collector
I1129 16:02:27.887075       1 event.go:307] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set kubernetes-dashboard-5c5cfc8747 to 1"
I1129 16:02:27.894318       1 event.go:307] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-5d78c9869d to 1"
I1129 16:02:27.910846       1 event.go:307] "Event occurred" object="ingress-nginx/ingress-nginx-controller" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set ingress-nginx-controller-5df97545c4 to 1"
I1129 16:02:27.981651       1 event.go:307] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set dashboard-metrics-scraper-5dd9cbfd69 to 1"
I1129 16:02:28.016736       1 job_controller.go:523] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1129 16:02:28.018996       1 job_controller.go:523] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1129 16:02:28.019100       1 event.go:307] "Event occurred" object="ingress-nginx/ingress-nginx-admission-patch" fieldPath="" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-admission-patch-b965k"
I1129 16:02:28.024461       1 event.go:307] "Event occurred" object="ingress-nginx/ingress-nginx-admission-create" fieldPath="" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-admission-create-56md6"
I1129 16:02:28.110704       1 event.go:307] "Event occurred" object="kube-system/kube-proxy" fieldPath="" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-ttsg8"
I1129 16:02:28.270626       1 job_controller.go:523] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1129 16:02:28.411941       1 job_controller.go:523] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1129 16:02:28.675809       1 event.go:307] "Event occurred" object="kube-system/coredns-5d78c9869d" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-5d78c9869d-cqtwj"
I1129 16:02:28.676203       1 event.go:307] "Event occurred" object="ingress-nginx/ingress-nginx-controller-5df97545c4" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-controller-5df97545c4-bqphk"
I1129 16:02:28.760133       1 job_controller.go:523] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1129 16:02:28.779203       1 event.go:307] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper-5dd9cbfd69" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: dashboard-metrics-scraper-5dd9cbfd69-5h8sc"
I1129 16:02:28.781421       1 event.go:307] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard-5c5cfc8747" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kubernetes-dashboard-5c5cfc8747-xjv27"
I1129 16:02:29.107054       1 job_controller.go:523] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1129 16:03:28.580657       1 event.go:307] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="NodeNotReady" message="Node minikube status is now: NodeNotReady"
I1129 16:03:29.131544       1 event.go:307] "Event occurred" object="kube-system/kube-scheduler-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I1129 16:03:29.642293       1 event.go:307] "Event occurred" object="kube-system/storage-provisioner" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I1129 16:03:30.033501       1 event.go:307] "Event occurred" object="kube-system/kube-proxy-ttsg8" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I1129 16:03:30.345282       1 event.go:307] "Event occurred" object="kube-system/coredns-5d78c9869d-cqtwj" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I1129 16:03:31.049485       1 event.go:307] "Event occurred" object="kube-system/etcd-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I1129 16:03:31.460930       1 controller_utils.go:151] "Failed to update status for pod" pod="kube-system/kube-apiserver-minikube" err="Operation cannot be fulfilled on pods \"kube-apiserver-minikube\": the object has been modified; please apply your changes to the latest version and try again"
I1129 16:03:31.468022       1 event.go:307] "Event occurred" object="kube-system/kube-apiserver-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
E1129 16:03:31.903018       1 node_lifecycle_controller.go:749] unable to mark all pods NotReady on node minikube: Operation cannot be fulfilled on pods "kube-apiserver-minikube": the object has been modified; please apply your changes to the latest version and try again; queuing for retry
I1129 16:03:31.907084       1 node_lifecycle_controller.go:1027] "Controller detected that all Nodes are not-Ready. Entering master disruption mode"
I1129 16:03:31.911560       1 event.go:307] "Event occurred" object="kube-system/kube-controller-manager-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I1129 16:03:45.708791       1 controller_utils.go:151] "Failed to update status for pod" pod="kube-system/kube-apiserver-minikube" err="etcdserver: request timed out"
I1129 16:03:45.709593       1 event.go:307] "Event occurred" object="kube-system/kube-apiserver-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I1129 16:03:49.201438       1 event.go:307] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper" fieldPath="" kind="Endpoints" apiVersion="v1" type="Warning" reason="FailedToUpdateEndpoint" message="Failed to update endpoint kubernetes-dashboard/dashboard-metrics-scraper: etcdserver: request timed out"
I1129 16:03:49.217291       1 event.go:298] Event(v1.ObjectReference{Kind:"Service", Namespace:"kubernetes-dashboard", Name:"dashboard-metrics-scraper", UID:"5bc130a1-b1d5-4bb9-8821-0805a0d19492", APIVersion:"v1", ResourceVersion:"1117", FieldPath:""}): type: 'Warning' reason: 'FailedToUpdateEndpointSlices' Error updating Endpoint Slices for Service kubernetes-dashboard/dashboard-metrics-scraper: failed to update dashboard-metrics-scraper-b7dbm EndpointSlice for Service kubernetes-dashboard/dashboard-metrics-scraper: etcdserver: request timed out
W1129 16:03:49.222222       1 endpointslice_controller.go:297] Error syncing endpoint slices for service "kubernetes-dashboard/dashboard-metrics-scraper", retrying. Error: failed to update dashboard-metrics-scraper-b7dbm EndpointSlice for Service kubernetes-dashboard/dashboard-metrics-scraper: etcdserver: request timed out
W1129 16:03:49.972229       1 topologycache.go:232] Can't get CPU or zone information for minikube node
I1129 16:03:50.116232       1 event.go:307] "Event occurred" object="kube-system/kube-scheduler-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I1129 16:03:50.413754       1 event.go:307] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper" fieldPath="" kind="Endpoints" apiVersion="v1" type="Warning" reason="FailedToUpdateEndpoint" message="Failed to update endpoint kubernetes-dashboard/dashboard-metrics-scraper: Operation cannot be fulfilled on endpoints \"dashboard-metrics-scraper\": the object has been modified; please apply your changes to the latest version and try again"
E1129 16:03:50.909297       1 node_lifecycle_controller.go:749] unable to mark all pods NotReady on node minikube: etcdserver: request timed out; queuing for retry
I1129 16:03:50.909489       1 event.go:307] "Event occurred" object="kube-system/storage-provisioner" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I1129 16:03:55.915123       1 node_lifecycle_controller.go:1046] "Controller detected that some Nodes are Ready. Exiting master disruption mode"
I1129 16:10:53.484098       1 event.go:307] "Event occurred" object="default/auth-depl" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set auth-depl-774f794f7 to 1"
I1129 16:10:53.555593       1 event.go:307] "Event occurred" object="default/auth-depl-774f794f7" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: auth-depl-774f794f7-2wvfn"
W1129 16:10:53.649476       1 endpointslice_controller.go:297] Error syncing endpoint slices for service "default/auth-srv", retrying. Error: EndpointSlice informer cache is out of date

* 
* ==> kube-proxy [268a1af1e0bc] <==
* I1129 16:02:43.918410       1 node.go:141] Successfully retrieved node IP: 192.168.58.2
I1129 16:02:43.920389       1 server_others.go:110] "Detected node IP" address="192.168.58.2"
I1129 16:02:43.920678       1 server_others.go:554] "Using iptables proxy"
I1129 16:02:44.950712       1 server_others.go:192] "Using iptables Proxier"
I1129 16:02:44.950857       1 server_others.go:199] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I1129 16:02:44.950940       1 server_others.go:200] "Creating dualStackProxier for iptables"
I1129 16:02:44.951068       1 server_others.go:484] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, defaulting to no-op detect-local for IPv6"
I1129 16:02:44.954299       1 proxier.go:253] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I1129 16:02:44.985498       1 server.go:658] "Version info" version="v1.27.3"
I1129 16:02:44.985568       1 server.go:660] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1129 16:02:45.035472       1 config.go:188] "Starting service config controller"
I1129 16:02:45.035513       1 shared_informer.go:311] Waiting for caches to sync for service config
I1129 16:02:45.047258       1 config.go:97] "Starting endpoint slice config controller"
I1129 16:02:45.047480       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I1129 16:02:45.051548       1 config.go:315] "Starting node config controller"
I1129 16:02:45.059594       1 shared_informer.go:311] Waiting for caches to sync for node config
I1129 16:02:45.260712       1 shared_informer.go:318] Caches are synced for node config
I1129 16:02:45.353957       1 shared_informer.go:318] Caches are synced for endpoint slice config
I1129 16:02:45.354169       1 shared_informer.go:318] Caches are synced for service config
I1129 16:04:18.666241       1 trace.go:219] Trace[2064294929]: "iptables ChainExists" (29-Nov-2023 16:04:15.129) (total time: 2669ms):
Trace[2064294929]: [2.669634331s] [2.669634331s] END
I1129 16:04:18.666241       1 trace.go:219] Trace[1017761852]: "iptables ChainExists" (29-Nov-2023 16:04:15.045) (total time: 2837ms):
Trace[1017761852]: [2.837456128s] [2.837456128s] END
I1129 16:04:49.573719       1 trace.go:219] Trace[753204762]: "iptables ChainExists" (29-Nov-2023 16:04:45.253) (total time: 4078ms):
Trace[753204762]: [4.078216955s] [4.078216955s] END
I1129 16:04:49.683625       1 trace.go:219] Trace[60572722]: "iptables ChainExists" (29-Nov-2023 16:04:45.253) (total time: 4190ms):
Trace[60572722]: [4.190776637s] [4.190776637s] END

* 
* ==> kube-scheduler [8ab073a12072] <==
* E1128 16:40:05.474765       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W1128 16:40:05.595972       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E1128 16:40:05.596054       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W1128 16:40:05.945185       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E1128 16:40:05.945296       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W1128 16:40:09.789608       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E1128 16:40:09.789699       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W1128 16:40:10.787271       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E1128 16:40:10.787368       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W1128 16:40:12.209108       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E1128 16:40:12.209195       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W1128 16:40:12.653028       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E1128 16:40:12.653104       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W1128 16:40:12.707281       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E1128 16:40:12.707720       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W1128 16:40:12.744207       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E1128 16:40:12.744583       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W1128 16:40:13.055501       1 reflector.go:533] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E1128 16:40:13.055571       1 reflector.go:148] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W1128 16:40:13.421302       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E1128 16:40:13.421360       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W1128 16:40:13.699079       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E1128 16:40:13.699181       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W1128 16:40:14.791163       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E1128 16:40:14.791696       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W1128 16:40:14.866863       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E1128 16:40:14.866944       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W1128 16:40:16.555725       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E1128 16:40:16.559730       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W1128 16:40:16.584475       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E1128 16:40:16.593565       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W1128 16:40:16.763743       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E1128 16:40:16.763844       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W1128 16:40:17.299097       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E1128 16:40:17.299168       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W1128 16:40:24.625519       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E1128 16:40:24.625612       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W1128 16:40:25.724031       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E1128 16:40:25.724094       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W1128 16:40:26.392052       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E1128 16:40:26.392127       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
I1128 16:40:36.641894       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
W1128 16:41:05.437337       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: Get "https://192.168.58.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.58.2:8443: connect: connection refused
E1128 16:41:05.437487       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.58.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.58.2:8443: connect: connection refused
E1128 16:41:18.597395       1 reflector.go:148] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: unknown (get configmaps)
E1128 16:41:18.649414       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: unknown (get storageclasses.storage.k8s.io)
E1128 16:41:18.649605       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: unknown (get pods)
W1128 16:41:18.678899       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found, clusterrole.rbac.authorization.k8s.io "system:public-info-viewer" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found, clusterrole.rbac.authorization.k8s.io "system:volume-scheduler" not found]
E1128 16:41:18.678994       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found, clusterrole.rbac.authorization.k8s.io "system:public-info-viewer" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found, clusterrole.rbac.authorization.k8s.io "system:volume-scheduler" not found]
E1128 16:41:18.679111       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: unknown (get services)
E1128 16:41:18.679317       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: unknown (get statefulsets.apps)
E1128 16:41:18.683290       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: unknown (get persistentvolumeclaims)
E1128 16:41:18.686079       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: unknown (get persistentvolumes)
E1128 16:41:18.688979       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: unknown (get nodes)
E1128 16:41:18.689442       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: unknown (get namespaces)
E1128 16:41:18.689600       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: unknown (get replicasets.apps)
W1128 16:41:18.689659       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:public-info-viewer" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found, clusterrole.rbac.authorization.k8s.io "system:volume-scheduler" not found, clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found]
E1128 16:41:18.689728       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:public-info-viewer" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found, clusterrole.rbac.authorization.k8s.io "system:volume-scheduler" not found, clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found]
E1128 16:41:18.693018       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: unknown (get replicationcontrollers)
E1128 16:41:18.702050       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: unknown (get csidrivers.storage.k8s.io) - error from a previous attempt: net/http: TLS handshake timeout

* 
* ==> kube-scheduler [d6ea74aebb4d] <==
* I1129 16:02:03.963693       1 serving.go:348] Generated self-signed cert in-memory
W1129 16:02:11.904551       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W1129 16:02:11.904676       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W1129 16:02:11.904719       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W1129 16:02:11.904765       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I1129 16:02:12.117222       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.27.3"
I1129 16:02:12.118535       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1129 16:02:12.140618       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I1129 16:02:12.140710       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I1129 16:02:12.152670       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I1129 16:02:12.163254       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I1129 16:02:12.284898       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* Nov 29 16:02:40 minikube kubelet[1324]: I1129 16:02:40.551869    1324 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="6eb639b6aee83f1379b5e80c41430fbdc7b7727611209c2125868bba31198c4b"
Nov 29 16:02:40 minikube kubelet[1324]: I1129 16:02:40.592154    1324 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="bec1bf5ed3c6700f387144a64f239aebba8b4217bc5d7a01d9a58c2073c5c7f3"
Nov 29 16:02:40 minikube kubelet[1324]: I1129 16:02:40.960063    1324 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-ttsg8" podStartSLOduration=13.850341048 podCreationTimestamp="2023-11-29 16:02:27 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-11-29 16:02:40.755677941 +0000 UTC m=+58.070183523" watchObservedRunningTime="2023-11-29 16:02:40.850341048 +0000 UTC m=+58.164846627"
Nov 29 16:02:44 minikube kubelet[1324]: I1129 16:02:44.135137    1324 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/storage-provisioner" podStartSLOduration=22.135049844 podCreationTimestamp="2023-11-29 16:02:22 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-11-29 16:02:41.011037994 +0000 UTC m=+58.325543586" watchObservedRunningTime="2023-11-29 16:02:44.135049844 +0000 UTC m=+61.449555410"
Nov 29 16:02:44 minikube kubelet[1324]: I1129 16:02:44.135366    1324 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-5d78c9869d-cqtwj" podStartSLOduration=16.135316636 podCreationTimestamp="2023-11-29 16:02:28 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-11-29 16:02:44.122322161 +0000 UTC m=+61.436827744" watchObservedRunningTime="2023-11-29 16:02:44.135316636 +0000 UTC m=+61.449822197"
Nov 29 16:03:04 minikube kubelet[1324]: E1129 16:03:04.402753    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:03:06 minikube kubelet[1324]: E1129 16:03:06.579978    1324 event.go:280] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-minikube.179c237d1fc8712f", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-minikube", UID:"d6174d6e58bd958b5bf67d5ec5cee444", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: HTTP probe failed with statuscode: 500", Source:v1.EventSource{Component:"kubelet", Host:"minikube"}, FirstTimestamp:time.Date(2023, time.November, 29, 16, 2, 59, 550318895, time.Local), LastTimestamp:time.Date(2023, time.November, 29, 16, 2, 59, 550318895, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'etcdserver: request timed out' (will not retry!)
Nov 29 16:03:11 minikube kubelet[1324]: E1129 16:03:11.414416    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:03:18 minikube kubelet[1324]: E1129 16:03:18.426529    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:03:25 minikube kubelet[1324]: E1129 16:03:25.437111    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:03:28 minikube kubelet[1324]: E1129 16:03:28.462218    1324 controller.go:193] "Failed to update lease" err="Operation cannot be fulfilled on leases.coordination.k8s.io \"minikube\": the object has been modified; please apply your changes to the latest version and try again"
Nov 29 16:03:28 minikube kubelet[1324]: I1129 16:03:28.845129    1324 controller.go:116] "failed to update lease using latest lease, fallback to ensure lease" err="failed 5 attempts to update lease"
Nov 29 16:03:29 minikube kubelet[1324]: I1129 16:03:29.290266    1324 scope.go:115] "RemoveContainer" containerID="560c03dac6e3746debc4487c37ab9b6b7b25668e3c4c0171ba95584a55c31bd5"
Nov 29 16:03:41 minikube kubelet[1324]: I1129 16:03:41.307787    1324 status_manager.go:833] "Failed to update status for pod" pod="kubernetes-dashboard/dashboard-metrics-scraper-5dd9cbfd69-5h8sc" err="failed to patch status \"{\\\"metadata\\\":{\\\"uid\\\":\\\"025da599-f705-4c9e-ad9a-79e44f1c4ecf\\\"},\\\"status\\\":{\\\"$setElementOrder/conditions\\\":[{\\\"type\\\":\\\"Initialized\\\"},{\\\"type\\\":\\\"Ready\\\"},{\\\"type\\\":\\\"ContainersReady\\\"},{\\\"type\\\":\\\"PodScheduled\\\"}],\\\"conditions\\\":[{\\\"lastTransitionTime\\\":\\\"2023-11-29T16:03:32Z\\\",\\\"message\\\":null,\\\"reason\\\":null,\\\"status\\\":\\\"True\\\",\\\"type\\\":\\\"Ready\\\"},{\\\"lastTransitionTime\\\":\\\"2023-11-29T16:03:32Z\\\",\\\"message\\\":null,\\\"reason\\\":null,\\\"status\\\":\\\"True\\\",\\\"type\\\":\\\"ContainersReady\\\"}],\\\"containerStatuses\\\":[{\\\"containerID\\\":\\\"docker://861918d2f1deaf2c1200c1c46b64b9c9288ad4584d2bce9615ba9fdbb0101977\\\",\\\"image\\\":\\\"kubernetesui/metrics-scraper@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c\\\",\\\"imageID\\\":\\\"docker-pullable://kubernetesui/metrics-scraper@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c\\\",\\\"lastState\\\":{},\\\"name\\\":\\\"dashboard-metrics-scraper\\\",\\\"ready\\\":true,\\\"restartCount\\\":0,\\\"started\\\":true,\\\"state\\\":{\\\"running\\\":{\\\"startedAt\\\":\\\"2023-11-29T16:03:31Z\\\"}}}],\\\"phase\\\":\\\"Running\\\",\\\"podIP\\\":\\\"10.244.0.2\\\",\\\"podIPs\\\":[{\\\"ip\\\":\\\"10.244.0.2\\\"}]}}\" for pod \"kubernetes-dashboard\"/\"dashboard-metrics-scraper-5dd9cbfd69-5h8sc\": etcdserver: request timed out"
Nov 29 16:03:47 minikube kubelet[1324]: E1129 16:03:47.889781    1324 kubelet_node_status.go:540] "Error updating node status, will retry" err="failed to patch status \"{\\\"status\\\":{\\\"$setElementOrder/conditions\\\":[{\\\"type\\\":\\\"MemoryPressure\\\"},{\\\"type\\\":\\\"DiskPressure\\\"},{\\\"type\\\":\\\"PIDPressure\\\"},{\\\"type\\\":\\\"Ready\\\"}],\\\"conditions\\\":[{\\\"lastHeartbeatTime\\\":\\\"2023-11-29T16:03:38Z\\\",\\\"lastTransitionTime\\\":\\\"2023-11-29T16:03:38Z\\\",\\\"message\\\":\\\"kubelet has sufficient memory available\\\",\\\"reason\\\":\\\"KubeletHasSufficientMemory\\\",\\\"status\\\":\\\"False\\\",\\\"type\\\":\\\"MemoryPressure\\\"},{\\\"lastHeartbeatTime\\\":\\\"2023-11-29T16:03:38Z\\\",\\\"lastTransitionTime\\\":\\\"2023-11-29T16:03:38Z\\\",\\\"message\\\":\\\"kubelet has no disk pressure\\\",\\\"reason\\\":\\\"KubeletHasNoDiskPressure\\\",\\\"status\\\":\\\"False\\\",\\\"type\\\":\\\"DiskPressure\\\"},{\\\"lastHeartbeatTime\\\":\\\"2023-11-29T16:03:38Z\\\",\\\"lastTransitionTime\\\":\\\"2023-11-29T16:03:38Z\\\",\\\"message\\\":\\\"kubelet has sufficient PID available\\\",\\\"reason\\\":\\\"KubeletHasSufficientPID\\\",\\\"status\\\":\\\"False\\\",\\\"type\\\":\\\"PIDPressure\\\"},{\\\"lastHeartbeatTime\\\":\\\"2023-11-29T16:03:38Z\\\",\\\"lastTransitionTime\\\":\\\"2023-11-29T16:03:38Z\\\",\\\"message\\\":\\\"kubelet is posting ready status\\\",\\\"reason\\\":\\\"KubeletReady\\\",\\\"status\\\":\\\"True\\\",\\\"type\\\":\\\"Ready\\\"}]}}\" for node \"minikube\": etcdserver: request timed out"
Nov 29 16:03:48 minikube kubelet[1324]: E1129 16:03:48.200528    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:03:49 minikube kubelet[1324]: I1129 16:03:49.096751    1324 status_manager.go:809] "Failed to get status for pod" podUID=f8fdea5a-3683-415b-9c74-ec15baad462d pod="kube-system/kube-proxy-ttsg8" err="etcdserver: request timed out"
Nov 29 16:03:49 minikube kubelet[1324]: E1129 16:03:49.104938    1324 event.go:280] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-apiserver-minikube.179c237d1fc8712f", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"1287", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-apiserver-minikube", UID:"d6174d6e58bd958b5bf67d5ec5cee444", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-apiserver}"}, Reason:"Unhealthy", Message:"Readiness probe failed: HTTP probe failed with statuscode: 500", Source:v1.EventSource{Component:"kubelet", Host:"minikube"}, FirstTimestamp:time.Date(2023, time.November, 29, 16, 2, 59, 0, time.Local), LastTimestamp:time.Date(2023, time.November, 29, 16, 3, 38, 725821824, time.Local), Count:8, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'etcdserver: request timed out' (will not retry!)
Nov 29 16:03:50 minikube kubelet[1324]: E1129 16:03:50.037155    1324 controller.go:193] "Failed to update lease" err="Operation cannot be fulfilled on leases.coordination.k8s.io \"minikube\": the object has been modified; please apply your changes to the latest version and try again"
Nov 29 16:04:13 minikube kubelet[1324]: E1129 16:04:13.799671    1324 kubelet.go:2431] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="1.166s"
Nov 29 16:04:17 minikube kubelet[1324]: E1129 16:04:17.716915    1324 kubelet.go:2431] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="1.085s"
Nov 29 16:04:18 minikube kubelet[1324]: E1129 16:04:18.421523    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:04:25 minikube kubelet[1324]: E1129 16:04:25.301757    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:04:26 minikube kubelet[1324]: E1129 16:04:26.161311    1324 controller.go:193] "Failed to update lease" err="Operation cannot be fulfilled on leases.coordination.k8s.io \"minikube\": the object has been modified; please apply your changes to the latest version and try again"
Nov 29 16:04:27 minikube kubelet[1324]: I1129 16:04:27.239630    1324 scope.go:115] "RemoveContainer" containerID="560c03dac6e3746debc4487c37ab9b6b7b25668e3c4c0171ba95584a55c31bd5"
Nov 29 16:04:27 minikube kubelet[1324]: I1129 16:04:27.240741    1324 scope.go:115] "RemoveContainer" containerID="5b035af680154ae2eafcf5e70a4dc467431f40431facbe841bf5597f631a5860"
Nov 29 16:04:27 minikube kubelet[1324]: E1129 16:04:27.246272    1324 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 10s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(38eea28a-0300-43a8-a089-0b4844c7c62d)\"" pod="kube-system/storage-provisioner" podUID=38eea28a-0300-43a8-a089-0b4844c7c62d
Nov 29 16:04:39 minikube kubelet[1324]: E1129 16:04:39.530783    1324 kubelet.go:2431] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="1.132s"
Nov 29 16:04:40 minikube kubelet[1324]: I1129 16:04:40.398245    1324 scope.go:115] "RemoveContainer" containerID="5b035af680154ae2eafcf5e70a4dc467431f40431facbe841bf5597f631a5860"
Nov 29 16:04:43 minikube kubelet[1324]: E1129 16:04:43.655223    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:04:50 minikube kubelet[1324]: I1129 16:04:50.911279    1324 status_manager.go:809] "Failed to get status for pod" podUID=38eea28a-0300-43a8-a089-0b4844c7c62d pod="kube-system/storage-provisioner" err="etcdserver: request timed out"
Nov 29 16:04:50 minikube kubelet[1324]: E1129 16:04:50.930499    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:04:50 minikube kubelet[1324]: E1129 16:04:50.913183    1324 event.go:280] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"storage-provisioner.179c2377e6011d48", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"1289", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"storage-provisioner", UID:"38eea28a-0300-43a8-a089-0b4844c7c62d", APIVersion:"v1", ResourceVersion:"1085", FieldPath:"spec.containers{storage-provisioner}"}, Reason:"Pulled", Message:"Container image \"gcr.io/k8s-minikube/storage-provisioner:v5\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"minikube"}, FirstTimestamp:time.Date(2023, time.November, 29, 16, 2, 37, 0, time.Local), LastTimestamp:time.Date(2023, time.November, 29, 16, 4, 40, 410800962, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'etcdserver: request timed out' (will not retry!)
Nov 29 16:04:53 minikube kubelet[1324]: E1129 16:04:53.443195    1324 controller.go:193] "Failed to update lease" err="Operation cannot be fulfilled on leases.coordination.k8s.io \"minikube\": the object has been modified; please apply your changes to the latest version and try again"
Nov 29 16:06:44 minikube kubelet[1324]: W1129 16:06:44.651996    1324 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Nov 29 16:10:53 minikube kubelet[1324]: I1129 16:10:53.749242    1324 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kubernetes-dashboard/kubernetes-dashboard-5c5cfc8747-xjv27" podStartSLOduration=373.481972119 podCreationTimestamp="2023-11-29 16:02:28 +0000 UTC" firstStartedPulling="2023-11-29 16:02:42.058108578 +0000 UTC m=+59.372614159" lastFinishedPulling="2023-11-29 16:04:54.305991935 +0000 UTC m=+191.619933923" observedRunningTime="2023-11-29 16:04:56.062655089 +0000 UTC m=+193.376597082" watchObservedRunningTime="2023-11-29 16:10:53.729291883 +0000 UTC m=+551.025595763"
Nov 29 16:10:53 minikube kubelet[1324]: I1129 16:10:53.752478    1324 topology_manager.go:212] "Topology Admit Handler"
Nov 29 16:10:53 minikube kubelet[1324]: I1129 16:10:53.870908    1324 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-4k9zv\" (UniqueName: \"kubernetes.io/projected/d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf-kube-api-access-4k9zv\") pod \"auth-depl-774f794f7-2wvfn\" (UID: \"d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf\") " pod="default/auth-depl-774f794f7-2wvfn"
Nov 29 16:10:55 minikube kubelet[1324]: I1129 16:10:55.344419    1324 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="93bffe3dc2fc91ac2b90fcb9b5c7a8e4e57aa9d2fd0e7b1aebeb30830ab1cb39"
Nov 29 16:11:08 minikube kubelet[1324]: E1129 16:11:08.394612    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:11:15 minikube kubelet[1324]: E1129 16:11:15.410571    1324 controller.go:193] "Failed to update lease" err="etcdserver: request timed out"
Nov 29 16:11:18 minikube kubelet[1324]: E1129 16:11:18.234791    1324 controller.go:193] "Failed to update lease" err="Operation cannot be fulfilled on leases.coordination.k8s.io \"minikube\": the object has been modified; please apply your changes to the latest version and try again"
Nov 29 16:11:19 minikube kubelet[1324]: I1129 16:11:19.098885    1324 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="default/auth-depl-774f794f7-2wvfn" podStartSLOduration=26.094927044 podCreationTimestamp="2023-11-29 16:10:53 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-11-29 16:10:58.339723078 +0000 UTC m=+555.636026960" watchObservedRunningTime="2023-11-29 16:11:19.094927044 +0000 UTC m=+576.386404819"
Nov 29 16:11:19 minikube kubelet[1324]: I1129 16:11:19.470302    1324 scope.go:115] "RemoveContainer" containerID="5b035af680154ae2eafcf5e70a4dc467431f40431facbe841bf5597f631a5860"
Nov 29 16:11:19 minikube kubelet[1324]: I1129 16:11:19.475624    1324 scope.go:115] "RemoveContainer" containerID="663c94037b00b34e0993dfcb71033495fe6221f9fac36bfcbe861f2d3a0ac413"
Nov 29 16:11:19 minikube kubelet[1324]: E1129 16:11:19.501696    1324 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(38eea28a-0300-43a8-a089-0b4844c7c62d)\"" pod="kube-system/storage-provisioner" podUID=38eea28a-0300-43a8-a089-0b4844c7c62d
Nov 29 16:11:30 minikube kubelet[1324]: I1129 16:11:30.436611    1324 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-4k9zv\" (UniqueName: \"kubernetes.io/projected/d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf-kube-api-access-4k9zv\") pod \"d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf\" (UID: \"d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf\") "
Nov 29 16:11:30 minikube kubelet[1324]: I1129 16:11:30.458493    1324 operation_generator.go:878] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf-kube-api-access-4k9zv" (OuterVolumeSpecName: "kube-api-access-4k9zv") pod "d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf" (UID: "d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf"). InnerVolumeSpecName "kube-api-access-4k9zv". PluginName "kubernetes.io/projected", VolumeGidValue ""
Nov 29 16:11:30 minikube kubelet[1324]: I1129 16:11:30.538506    1324 reconciler_common.go:300] "Volume detached for volume \"kube-api-access-4k9zv\" (UniqueName: \"kubernetes.io/projected/d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf-kube-api-access-4k9zv\") on node \"minikube\" DevicePath \"\""
Nov 29 16:11:31 minikube kubelet[1324]: I1129 16:11:31.000253    1324 scope.go:115] "RemoveContainer" containerID="a0badaa27694fb3448cedceff4973951db667a27d250ec78e7420d1110661373"
Nov 29 16:11:31 minikube kubelet[1324]: I1129 16:11:31.658883    1324 scope.go:115] "RemoveContainer" containerID="663c94037b00b34e0993dfcb71033495fe6221f9fac36bfcbe861f2d3a0ac413"
Nov 29 16:11:31 minikube kubelet[1324]: E1129 16:11:31.659708    1324 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 20s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(38eea28a-0300-43a8-a089-0b4844c7c62d)\"" pod="kube-system/storage-provisioner" podUID=38eea28a-0300-43a8-a089-0b4844c7c62d
Nov 29 16:11:32 minikube kubelet[1324]: I1129 16:11:32.689229    1324 kubelet_volumes.go:161] "Cleaned up orphaned pod volumes dir" podUID=d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf path="/var/lib/kubelet/pods/d5dc9ba6-7ac9-41ee-89b8-5b362b3a0edf/volumes"
Nov 29 16:11:43 minikube kubelet[1324]: I1129 16:11:43.658647    1324 scope.go:115] "RemoveContainer" containerID="663c94037b00b34e0993dfcb71033495fe6221f9fac36bfcbe861f2d3a0ac413"
Nov 29 16:11:44 minikube kubelet[1324]: W1129 16:11:44.675841    1324 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Nov 29 16:11:45 minikube kubelet[1324]: I1129 16:11:45.786565    1324 scope.go:115] "RemoveContainer" containerID="663c94037b00b34e0993dfcb71033495fe6221f9fac36bfcbe861f2d3a0ac413"
Nov 29 16:16:44 minikube kubelet[1324]: W1129 16:16:44.664653    1324 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Nov 29 16:21:44 minikube kubelet[1324]: W1129 16:21:44.664311    1324 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Nov 29 16:26:44 minikube kubelet[1324]: W1129 16:26:44.679173    1324 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Nov 29 16:31:44 minikube kubelet[1324]: W1129 16:31:44.743104    1324 sysinfo.go:203] Nodes topology is not available, providing CPU topology

* 
* ==> kubernetes-dashboard [158a771c2b8d] <==
* 2023/11/29 16:04:55 Using namespace: kubernetes-dashboard
2023/11/29 16:04:55 Using in-cluster config to connect to apiserver
2023/11/29 16:04:55 Using secret token for csrf signing
2023/11/29 16:04:55 Initializing csrf token from kubernetes-dashboard-csrf secret
2023/11/29 16:04:55 Empty token. Generating and storing in a secret kubernetes-dashboard-csrf
2023/11/29 16:04:55 Successful initial request to the apiserver, version: v1.27.3
2023/11/29 16:04:55 Generating JWE encryption key
2023/11/29 16:04:55 New synchronizer has been registered: kubernetes-dashboard-key-holder-kubernetes-dashboard. Starting
2023/11/29 16:04:55 Starting secret synchronizer for kubernetes-dashboard-key-holder in namespace kubernetes-dashboard
2023/11/29 16:04:56 Initializing JWE encryption key from synchronized object
2023/11/29 16:04:56 Creating in-cluster Sidecar client
2023/11/29 16:04:56 Serving insecurely on HTTP port: 9090
2023/11/29 16:04:56 Successful request to sidecar
2023/11/29 16:04:55 Starting overwatch

* 
* ==> storage-provisioner [a1aa3e544b1c] <==
* I1129 16:11:44.841091       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I1129 16:11:45.007087       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I1129 16:11:45.007889       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I1129 16:12:03.511134       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I1129 16:12:03.512022       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_de6e586c-26f8-4d4c-93f3-09284f34605f!
I1129 16:12:03.516223       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"e19392a6-c5db-4784-aaac-567d13711a36", APIVersion:"v1", ResourceVersion:"1733", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_de6e586c-26f8-4d4c-93f3-09284f34605f became leader
I1129 16:12:03.613519       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_de6e586c-26f8-4d4c-93f3-09284f34605f!

